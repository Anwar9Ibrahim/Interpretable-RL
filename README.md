# Interpretable-RL
In this project:
I Developed an interpretable reinforcement learning agent for OpenAI Gym's Pong, balancing performance and transparency. Used Python, PyTorch, NumPy, OpenCV, Tkinter, and Matplotlib for implementation and visualization. Employed saliency maps, Q-value analysis, and Transformer model integration for improved interpretability, contributing to transparent AI advancements.

The folowing are the results of the training process and how the duration of the episode decresses as the models imporves..
![image](https://github.com/Anwar9Ibrahim/Interpretable-RL/assets/115429214/09950201-12be-4b78-9310-0d0322427ef4)


I also applied post-hoc interpretablity approach where i used different tools, such as "Saliency maps" and "mathematical approach" to predict the expected place of the padel at a specific timestep, also the q-values to decide which action will give us the most reward, and we created an interpretability board, to show our results:
![image](https://github.com/Anwar9Ibrahim/Interpretable-RL/assets/115429214/6ba54bb8-21be-47e4-9794-0bb8c2d228a3)

![image](https://github.com/Anwar9Ibrahim/Interpretable-RL/assets/115429214/657adc70-dd1f-457a-bf77-7f2d8683f2b4)




