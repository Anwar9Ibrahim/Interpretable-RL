{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "OpenAIPong-DQN.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install gym[all]\n",
        "!pip install -U gym[atari,accept-rom-license]\n",
        "!AutoROM --accept-license"
      ],
      "metadata": {
        "id": "L5BfuSDfg6Rr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q4AS7njD7iL6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a0e0f533-4714-42fb-f8c4-d44a93e3e37f"
      },
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fri Feb  3 15:13:49 2023       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 510.47.03    Driver Version: 510.47.03    CUDA Version: 11.6     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   67C    P0    29W /  70W |      0MiB / 15360MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-D98CddQuwKG"
      },
      "source": [
        "import gym\n",
        "import cv2\n",
        "\n",
        "import time\n",
        "import json\n",
        "import random\n",
        "import numpy as np\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "\n",
        "from collections import deque"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I8rGMlN2uzgk"
      },
      "source": [
        "ENVIRONMENT = \"PongDeterministic-v4\"\n",
        "\n",
        "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "SAVE_MODELS = True  # Save models to file so you can test later\n",
        "MODEL_PATH = \"./pong-cnn-\"  # Models path for saving or loading\n",
        "SAVE_MODEL_INTERVAL = 10  # Save models at every X epoch\n",
        "TRAIN_MODEL = True  # Train model while playing (Make it False when testing a model)\n",
        "\n",
        "LOAD_MODEL_FROM_FILE = False  # Load model from file\n",
        "LOAD_FILE_EPISODE = 0  # Load Xth episode from file\n",
        "\n",
        "BATCH_SIZE = 64  # Minibatch size that select randomly from mem for train nets\n",
        "MAX_EPISODE = 100000  # Max episode\n",
        "MAX_STEP = 100000  # Max step size for one episode\n",
        "\n",
        "MAX_MEMORY_LEN = 50000  # Max memory len\n",
        "MIN_MEMORY_LEN = 40000  # Min memory len before start train\n",
        "\n",
        "GAMMA = 0.97  # Discount rate\n",
        "ALPHA = 0.00025  # Learning rate\n",
        "EPSILON_DECAY = 0.99  # Epsilon decay rate by step\n",
        "\n",
        "RENDER_GAME_WINDOW = False  # Opens a new window to render the game (Won't work on colab default)"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HxF5-bzUu1q-"
      },
      "source": [
        "class DuelCNN(nn.Module):\n",
        "    \"\"\"\n",
        "    CNN with Duel Algo. https://arxiv.org/abs/1511.06581\n",
        "    \"\"\"\n",
        "    def __init__(self, h, w, output_size):\n",
        "        super(DuelCNN, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(in_channels=4,  out_channels=32, kernel_size=8, stride=4)\n",
        "        self.bn1 = nn.BatchNorm2d(32)\n",
        "        convw, convh = self.conv2d_size_calc(w, h, kernel_size=8, stride=4)\n",
        "        self.conv2 = nn.Conv2d(in_channels=32, out_channels=64, kernel_size=4, stride=2)\n",
        "        self.bn2 = nn.BatchNorm2d(64)\n",
        "        convw, convh = self.conv2d_size_calc(convw, convh, kernel_size=4, stride=2)\n",
        "        self.conv3 = nn.Conv2d(in_channels=64, out_channels=64, kernel_size=3, stride=1)\n",
        "        self.bn3 = nn.BatchNorm2d(64)\n",
        "        convw, convh = self.conv2d_size_calc(convw, convh, kernel_size=3, stride=1)\n",
        "\n",
        "        linear_input_size = convw * convh * 64  # Last conv layer's out sizes\n",
        "\n",
        "        # Action layer\n",
        "        self.Alinear1 = nn.Linear(in_features=linear_input_size, out_features=128)\n",
        "        self.Alrelu = nn.LeakyReLU()  # Linear 1 activation funct\n",
        "        self.Alinear2 = nn.Linear(in_features=128, out_features=output_size)\n",
        "\n",
        "        # State Value layer\n",
        "        self.Vlinear1 = nn.Linear(in_features=linear_input_size, out_features=128)\n",
        "        self.Vlrelu = nn.LeakyReLU()  # Linear 1 activation funct\n",
        "        self.Vlinear2 = nn.Linear(in_features=128, out_features=1)  # Only 1 node\n",
        "\n",
        "    def conv2d_size_calc(self, w, h, kernel_size=5, stride=2):\n",
        "        \"\"\"\n",
        "        Calcs conv layers output image sizes\n",
        "        \"\"\"\n",
        "        next_w = (w - (kernel_size - 1) - 1) // stride + 1\n",
        "        next_h = (h - (kernel_size - 1) - 1) // stride + 1\n",
        "        return next_w, next_h\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = F.relu(self.bn1(self.conv1(x)))\n",
        "        x = F.relu(self.bn2(self.conv2(x)))\n",
        "        x = F.relu(self.bn3(self.conv3(x)))\n",
        "\n",
        "        x = x.view(x.size(0), -1)  # Flatten every batch\n",
        "\n",
        "        Ax = self.Alrelu(self.Alinear1(x))\n",
        "        Ax = self.Alinear2(Ax)  # No activation on last layer\n",
        "\n",
        "        Vx = self.Vlrelu(self.Vlinear1(x))\n",
        "        Vx = self.Vlinear2(Vx)  # No activation on last layer\n",
        "\n",
        "        q = Vx + (Ax - Ax.mean())\n",
        "\n",
        "        return q"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "plT51MPbu5U5"
      },
      "source": [
        "class Agent:\n",
        "    def __init__(self, environment):\n",
        "        \"\"\"\n",
        "        Hyperparameters definition for Agent\n",
        "        \"\"\"\n",
        "        # State size for breakout env. SS images (210, 160, 3). Used as input size in network\n",
        "        self.state_size_h = environment.observation_space.shape[0]\n",
        "        self.state_size_w = environment.observation_space.shape[1]\n",
        "        self.state_size_c = environment.observation_space.shape[2]\n",
        "\n",
        "        # Activation size for breakout env. Used as output size in network\n",
        "        self.action_size = environment.action_space.n\n",
        "\n",
        "        # Image pre process params\n",
        "        self.target_h = 80  # Height after process\n",
        "        self.target_w = 64  # Widht after process\n",
        "\n",
        "        self.crop_dim = [20, self.state_size_h, 0, self.state_size_w]  # Cut 20 px from top to get rid of the score table\n",
        "\n",
        "        # Trust rate to our experiences\n",
        "        self.gamma = GAMMA  # Discount coef for future predictions\n",
        "        self.alpha = ALPHA  # Learning Rate\n",
        "\n",
        "        # After many experinces epsilon will be 0.05\n",
        "        # So we will do less Explore more Exploit\n",
        "        self.epsilon = 1  # Explore or Exploit\n",
        "        self.epsilon_decay = EPSILON_DECAY  # Adaptive Epsilon Decay Rate\n",
        "        self.epsilon_minimum = 0.05  # Minimum for Explore\n",
        "\n",
        "        # Deque holds replay mem.\n",
        "        self.memory = deque(maxlen=MAX_MEMORY_LEN)\n",
        "\n",
        "        # Create two model for DDQN algorithm\n",
        "        self.online_model = DuelCNN(h=self.target_h, w=self.target_w, output_size=self.action_size).to(DEVICE)\n",
        "        self.target_model = DuelCNN(h=self.target_h, w=self.target_w, output_size=self.action_size).to(DEVICE)\n",
        "        self.target_model.load_state_dict(self.online_model.state_dict())\n",
        "        self.target_model.eval()\n",
        "\n",
        "        # Adam used as optimizer\n",
        "        self.optimizer = optim.Adam(self.online_model.parameters(), lr=self.alpha)\n",
        "\n",
        "    def preProcess(self, image):\n",
        "        \"\"\"\n",
        "        Process image crop resize, grayscale and normalize the images\n",
        "        \"\"\"\n",
        "        frame = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)  # To grayscale\n",
        "        frame = frame[self.crop_dim[0]:self.crop_dim[1], self.crop_dim[2]:self.crop_dim[3]]  # Cut 20 px from top\n",
        "        frame = cv2.resize(frame, (self.target_w, self.target_h))  # Resize\n",
        "        frame = frame.reshape(self.target_w, self.target_h) / 255  # Normalize\n",
        "\n",
        "        return frame\n",
        "\n",
        "    def act(self, state):\n",
        "        \"\"\"\n",
        "        Get state and do action\n",
        "        Two option can be selectedd if explore select random action\n",
        "        if exploit ask nnet for action\n",
        "        \"\"\"\n",
        "\n",
        "        act_protocol = 'Explore' if random.uniform(0, 1) <= self.epsilon else 'Exploit'\n",
        "\n",
        "        if act_protocol == 'Explore':\n",
        "            action = random.randrange(self.action_size)\n",
        "        else:\n",
        "            with torch.no_grad():\n",
        "                state = torch.tensor(state, dtype=torch.float, device=DEVICE).unsqueeze(0)\n",
        "                q_values = self.online_model.forward(state)  # (1, action_size)\n",
        "                action = torch.argmax(q_values).item()  # Returns the indices of the maximum value of all elements\n",
        "\n",
        "        return action\n",
        "\n",
        "    def train(self):\n",
        "        \"\"\"\n",
        "        Train neural nets with replay memory\n",
        "        returns loss and max_q val predicted from online_net\n",
        "        \"\"\"\n",
        "        if len(agent.memory) < MIN_MEMORY_LEN:\n",
        "            loss, max_q = [0, 0]\n",
        "            return loss, max_q\n",
        "        # We get out minibatch and turn it to numpy array\n",
        "        state, action, reward, next_state, done = zip(*random.sample(self.memory, BATCH_SIZE))\n",
        "\n",
        "        # Concat batches in one array\n",
        "        # (np.arr, np.arr) ==> np.BIGarr\n",
        "        state = np.concatenate(state)\n",
        "        next_state = np.concatenate(next_state)\n",
        "\n",
        "        # Convert them to tensors\n",
        "        state = torch.tensor(state, dtype=torch.float, device=DEVICE)\n",
        "        next_state = torch.tensor(next_state, dtype=torch.float, device=DEVICE)\n",
        "        action = torch.tensor(action, dtype=torch.long, device=DEVICE)\n",
        "        reward = torch.tensor(reward, dtype=torch.float, device=DEVICE)\n",
        "        done = torch.tensor(done, dtype=torch.float, device=DEVICE)\n",
        "\n",
        "        # Make predictions\n",
        "        state_q_values = self.online_model(state)\n",
        "        next_states_q_values = self.online_model(next_state)\n",
        "        next_states_target_q_values = self.target_model(next_state)\n",
        "\n",
        "        # Find selected action's q_value\n",
        "        selected_q_value = state_q_values.gather(1, action.unsqueeze(1)).squeeze(1)\n",
        "        # Get indice of the max value of next_states_q_values\n",
        "        # Use that indice to get a q_value from next_states_target_q_values\n",
        "        # We use greedy for policy So it called off-policy\n",
        "        next_states_target_q_value = next_states_target_q_values.gather(1, next_states_q_values.max(1)[1].unsqueeze(1)).squeeze(1)\n",
        "        # Use Bellman function to find expected q value\n",
        "        expected_q_value = reward + self.gamma * next_states_target_q_value * (1 - done)\n",
        "\n",
        "        # Calc loss with expected_q_value and q_value\n",
        "        loss = (selected_q_value - expected_q_value.detach()).pow(2).mean()\n",
        "\n",
        "        self.optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        self.optimizer.step()\n",
        "\n",
        "        return loss, torch.max(state_q_values).item()\n",
        "\n",
        "    def storeResults(self, state, action, reward, nextState, done):\n",
        "        \"\"\"\n",
        "        Store every result to memory\n",
        "        \"\"\"\n",
        "        self.memory.append([state[None, :], action, reward, nextState[None, :], done])\n",
        "\n",
        "    def adaptiveEpsilon(self):\n",
        "        \"\"\"\n",
        "        Adaptive Epsilon means every step\n",
        "        we decrease the epsilon so we do less Explore\n",
        "        \"\"\"\n",
        "        if self.epsilon > self.epsilon_minimum:\n",
        "            self.epsilon *= self.epsilon_decay"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "environment = gym.make(ENVIRONMENT,  render_mode='rgb_array')  # Get env\n",
        "agent = Agent(environment)  # Create Agent\n",
        "\n",
        "if LOAD_MODEL_FROM_FILE:\n",
        "    agent.online_model.load_state_dict(torch.load(MODEL_PATH+str(LOAD_FILE_EPISODE)+\".pkl\"))\n",
        "\n",
        "    with open(MODEL_PATH+str(LOAD_FILE_EPISODE)+'.json') as outfile:\n",
        "        param = json.load(outfile)\n",
        "        agent.epsilon = param.get('epsilon')\n",
        "\n",
        "    startEpisode = LOAD_FILE_EPISODE + 1\n",
        "\n",
        "else:\n",
        "    startEpisode = 1\n",
        "\n",
        "last_100_ep_reward = deque(maxlen=100)  # Last 100 episode rewards\n",
        "total_step = 1  # Cumulkative sum of all steps in episodes\n",
        "for episode in range(startEpisode, MAX_EPISODE):\n",
        "\n",
        "    startTime = time.time()  # Keep time\n",
        "    state = environment.reset()  # Reset env\n",
        "    state= environment.render()\n",
        "\n",
        "    state = agent.preProcess(state)  # Process image\n",
        "\n",
        "    # Stack state . Every state contains 4 time contionusly frames\n",
        "    # We stack frames like 4 channel image\n",
        "    state = np.stack((state, state, state, state))\n",
        "\n",
        "    total_max_q_val = 0  # Total max q vals\n",
        "    total_reward = 0  # Total reward for each episode\n",
        "    total_loss = 0  # Total loss for each episode\n",
        "    for step in range(MAX_STEP):\n",
        "\n",
        "        if RENDER_GAME_WINDOW:\n",
        "            environment.render()  # Show state visually\n",
        "\n",
        "        # Select and perform an action\n",
        "        action = agent.act(state)  # Act\n",
        "        next_state, reward, done,_,  info = environment.step(action)  # Observe\n",
        "\n",
        "        next_state = agent.preProcess(next_state)  # Process image\n",
        "\n",
        "        # Stack state . Every state contains 4 time contionusly frames\n",
        "        # We stack frames like 4 channel image\n",
        "        next_state = np.stack((next_state, state[0], state[1], state[2]))\n",
        "\n",
        "        # Store the transition in memory\n",
        "        agent.storeResults(state, action, reward, next_state, done)  # Store to mem\n",
        "\n",
        "        # Move to the next state\n",
        "        state = next_state  # Update state\n",
        "\n",
        "        if TRAIN_MODEL:\n",
        "            # Perform one step of the optimization (on the target network)\n",
        "            loss, max_q_val = agent.train()  # Train with random BATCH_SIZE state taken from mem\n",
        "        else:\n",
        "            loss, max_q_val = [0, 0]\n",
        "\n",
        "        total_loss += loss\n",
        "        total_max_q_val += max_q_val\n",
        "        total_reward += reward\n",
        "        total_step += 1\n",
        "        if total_step % 1000 == 0:\n",
        "            agent.adaptiveEpsilon()  # Decrase epsilon\n",
        "\n",
        "        if done:  # Episode completed\n",
        "            currentTime = time.time()  # Keep current time\n",
        "            time_passed = currentTime - startTime  # Find episode duration\n",
        "            current_time_format = time.strftime(\"%H:%M:%S\", time.gmtime())  # Get current dateTime as HH:MM:SS\n",
        "            epsilonDict = {'epsilon': agent.epsilon}  # Create epsilon dict to save model as file\n",
        "\n",
        "            if SAVE_MODELS and episode % SAVE_MODEL_INTERVAL == 0:  # Save model as file\n",
        "                weightsPath = MODEL_PATH + str(episode) + '.pkl'\n",
        "                epsilonPath = MODEL_PATH + str(episode) + '.json'\n",
        "\n",
        "                torch.save(agent.online_model.state_dict(), weightsPath)\n",
        "                with open(epsilonPath, 'w') as outfile:\n",
        "                    json.dump(epsilonDict, outfile)\n",
        "\n",
        "            if TRAIN_MODEL:\n",
        "                agent.target_model.load_state_dict(agent.online_model.state_dict())  # Update target model\n",
        "\n",
        "            last_100_ep_reward.append(total_reward)\n",
        "            avg_max_q_val = total_max_q_val / step\n",
        "\n",
        "            outStr = \"Episode:{} Time:{} Reward:{:.2f} Loss:{:.2f} Last_100_Avg_Rew:{:.3f} Avg_Max_Q:{:.3f} Epsilon:{:.2f} Duration:{:.2f} Step:{} CStep:{}\".format(\n",
        "                episode, current_time_format, total_reward, total_loss, np.mean(last_100_ep_reward), avg_max_q_val, agent.epsilon, time_passed, step, total_step\n",
        "            )\n",
        "\n",
        "            print(outStr)\n",
        "\n",
        "            if SAVE_MODELS:\n",
        "                outputPath = MODEL_PATH + \"out\" + '.txt'  # Save outStr to file\n",
        "                with open(outputPath, 'a') as outfile:\n",
        "                    outfile.write(outStr+\"\\n\")\n",
        "\n",
        "            break\n"
      ],
      "metadata": {
        "id": "LDjpJJzH1MXJ",
        "outputId": "bb51c454-9089-46d9-e9b5-1801100fedfd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/gym/utils/passive_env_checker.py:289: UserWarning: \u001b[33mWARN: No render fps was declared in the environment (env.metadata['render_fps'] is None or not defined), rendering may occur at inconsistent fps.\u001b[0m\n",
            "  logger.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Episode:1 Time:15:14:05 Reward:-19.00 Loss:0.00 Last_100_Avg_Rew:-19.000 Avg_Max_Q:0.000 Epsilon:0.99 Duration:8.65 Step:1058 CStep:1060\n",
            "Episode:2 Time:15:14:06 Reward:-20.00 Loss:0.00 Last_100_Avg_Rew:-19.500 Avg_Max_Q:0.000 Epsilon:0.99 Duration:0.82 Step:922 CStep:1983\n",
            "Episode:3 Time:15:14:07 Reward:-21.00 Loss:0.00 Last_100_Avg_Rew:-20.000 Avg_Max_Q:0.000 Epsilon:0.98 Duration:0.75 Step:792 CStep:2776\n",
            "Episode:4 Time:15:14:08 Reward:-19.00 Loss:0.00 Last_100_Avg_Rew:-19.750 Avg_Max_Q:0.000 Epsilon:0.97 Duration:1.06 Step:1116 CStep:3893\n",
            "Episode:5 Time:15:14:09 Reward:-20.00 Loss:0.00 Last_100_Avg_Rew:-19.800 Avg_Max_Q:0.000 Epsilon:0.96 Duration:0.86 Step:897 CStep:4791\n",
            "Episode:6 Time:15:14:10 Reward:-21.00 Loss:0.00 Last_100_Avg_Rew:-20.000 Avg_Max_Q:0.000 Epsilon:0.95 Duration:0.79 Step:823 CStep:5615\n",
            "Episode:7 Time:15:14:10 Reward:-20.00 Loss:0.00 Last_100_Avg_Rew:-20.000 Avg_Max_Q:0.000 Epsilon:0.94 Duration:0.79 Step:841 CStep:6457\n",
            "Episode:8 Time:15:14:11 Reward:-21.00 Loss:0.00 Last_100_Avg_Rew:-20.125 Avg_Max_Q:0.000 Epsilon:0.93 Duration:0.96 Step:992 CStep:7450\n",
            "Episode:9 Time:15:14:13 Reward:-20.00 Loss:0.00 Last_100_Avg_Rew:-20.111 Avg_Max_Q:0.000 Epsilon:0.92 Duration:1.04 Step:1036 CStep:8487\n",
            "Episode:10 Time:15:14:13 Reward:-21.00 Loss:0.00 Last_100_Avg_Rew:-20.200 Avg_Max_Q:0.000 Epsilon:0.91 Duration:0.79 Step:791 CStep:9279\n",
            "Episode:11 Time:15:14:14 Reward:-20.00 Loss:0.00 Last_100_Avg_Rew:-20.182 Avg_Max_Q:0.000 Epsilon:0.90 Duration:0.89 Step:947 CStep:10227\n",
            "Episode:12 Time:15:14:15 Reward:-21.00 Loss:0.00 Last_100_Avg_Rew:-20.250 Avg_Max_Q:0.000 Epsilon:0.90 Duration:1.03 Step:1079 CStep:11307\n",
            "Episode:13 Time:15:14:16 Reward:-21.00 Loss:0.00 Last_100_Avg_Rew:-20.308 Avg_Max_Q:0.000 Epsilon:0.89 Duration:0.80 Step:823 CStep:12131\n",
            "Episode:14 Time:15:14:17 Reward:-20.00 Loss:0.00 Last_100_Avg_Rew:-20.286 Avg_Max_Q:0.000 Epsilon:0.88 Duration:0.99 Step:991 CStep:13123\n",
            "Episode:15 Time:15:14:18 Reward:-21.00 Loss:0.00 Last_100_Avg_Rew:-20.333 Avg_Max_Q:0.000 Epsilon:0.88 Duration:0.85 Step:825 CStep:13949\n",
            "Episode:16 Time:15:14:19 Reward:-20.00 Loss:0.00 Last_100_Avg_Rew:-20.312 Avg_Max_Q:0.000 Epsilon:0.87 Duration:0.84 Step:841 CStep:14791\n",
            "Episode:17 Time:15:14:20 Reward:-20.00 Loss:0.00 Last_100_Avg_Rew:-20.294 Avg_Max_Q:0.000 Epsilon:0.86 Duration:0.88 Step:903 CStep:15695\n",
            "Episode:18 Time:15:14:21 Reward:-20.00 Loss:0.00 Last_100_Avg_Rew:-20.278 Avg_Max_Q:0.000 Epsilon:0.85 Duration:0.92 Step:902 CStep:16598\n",
            "Episode:19 Time:15:14:21 Reward:-21.00 Loss:0.00 Last_100_Avg_Rew:-20.316 Avg_Max_Q:0.000 Epsilon:0.84 Duration:0.97 Step:977 CStep:17576\n",
            "Episode:20 Time:15:14:22 Reward:-21.00 Loss:0.00 Last_100_Avg_Rew:-20.350 Avg_Max_Q:0.000 Epsilon:0.83 Duration:0.84 Step:823 CStep:18400\n",
            "Episode:21 Time:15:14:23 Reward:-21.00 Loss:0.00 Last_100_Avg_Rew:-20.381 Avg_Max_Q:0.000 Epsilon:0.83 Duration:0.87 Step:823 CStep:19224\n",
            "Episode:22 Time:15:14:24 Reward:-21.00 Loss:0.00 Last_100_Avg_Rew:-20.409 Avg_Max_Q:0.000 Epsilon:0.82 Duration:0.92 Step:823 CStep:20048\n",
            "Episode:23 Time:15:14:25 Reward:-21.00 Loss:0.00 Last_100_Avg_Rew:-20.435 Avg_Max_Q:0.000 Epsilon:0.82 Duration:0.94 Step:883 CStep:20932\n",
            "Episode:24 Time:15:14:26 Reward:-21.00 Loss:0.00 Last_100_Avg_Rew:-20.458 Avg_Max_Q:0.000 Epsilon:0.81 Duration:0.98 Step:914 CStep:21847\n",
            "Episode:25 Time:15:14:27 Reward:-20.00 Loss:0.00 Last_100_Avg_Rew:-20.440 Avg_Max_Q:0.000 Epsilon:0.80 Duration:0.94 Step:841 CStep:22689\n",
            "Episode:26 Time:15:14:28 Reward:-20.00 Loss:0.00 Last_100_Avg_Rew:-20.423 Avg_Max_Q:0.000 Epsilon:0.79 Duration:1.13 Step:1019 CStep:23709\n",
            "Episode:27 Time:15:14:29 Reward:-20.00 Loss:0.00 Last_100_Avg_Rew:-20.407 Avg_Max_Q:0.000 Epsilon:0.79 Duration:1.06 Step:949 CStep:24659\n",
            "Episode:28 Time:15:14:30 Reward:-21.00 Loss:0.00 Last_100_Avg_Rew:-20.429 Avg_Max_Q:0.000 Epsilon:0.78 Duration:0.84 Step:782 CStep:25442\n",
            "Episode:29 Time:15:14:31 Reward:-19.00 Loss:0.00 Last_100_Avg_Rew:-20.379 Avg_Max_Q:0.000 Epsilon:0.77 Duration:1.33 Step:1207 CStep:26650\n",
            "Episode:30 Time:15:14:32 Reward:-21.00 Loss:0.00 Last_100_Avg_Rew:-20.400 Avg_Max_Q:0.000 Epsilon:0.76 Duration:0.94 Step:824 CStep:27475\n",
            "Episode:31 Time:15:14:33 Reward:-21.00 Loss:0.00 Last_100_Avg_Rew:-20.419 Avg_Max_Q:0.000 Epsilon:0.75 Duration:1.00 Step:883 CStep:28359\n",
            "Episode:32 Time:15:14:34 Reward:-20.00 Loss:0.00 Last_100_Avg_Rew:-20.406 Avg_Max_Q:0.000 Epsilon:0.75 Duration:1.02 Step:899 CStep:29259\n",
            "Episode:33 Time:15:14:35 Reward:-21.00 Loss:0.00 Last_100_Avg_Rew:-20.424 Avg_Max_Q:0.000 Epsilon:0.74 Duration:0.91 Step:823 CStep:30083\n",
            "Episode:34 Time:15:14:36 Reward:-21.00 Loss:0.00 Last_100_Avg_Rew:-20.441 Avg_Max_Q:0.000 Epsilon:0.74 Duration:1.03 Step:885 CStep:30969\n",
            "Episode:35 Time:15:14:37 Reward:-21.00 Loss:0.00 Last_100_Avg_Rew:-20.457 Avg_Max_Q:0.000 Epsilon:0.72 Duration:1.21 Step:1035 CStep:32005\n",
            "Episode:36 Time:15:14:39 Reward:-21.00 Loss:0.00 Last_100_Avg_Rew:-20.472 Avg_Max_Q:0.000 Epsilon:0.72 Duration:1.06 Step:825 CStep:32831\n",
            "Episode:37 Time:15:14:39 Reward:-21.00 Loss:0.00 Last_100_Avg_Rew:-20.486 Avg_Max_Q:0.000 Epsilon:0.72 Duration:0.92 Step:782 CStep:33614\n",
            "Episode:38 Time:15:14:41 Reward:-21.00 Loss:0.00 Last_100_Avg_Rew:-20.500 Avg_Max_Q:0.000 Epsilon:0.71 Duration:1.19 Step:973 CStep:34588\n",
            "Episode:39 Time:15:14:42 Reward:-21.00 Loss:0.00 Last_100_Avg_Rew:-20.513 Avg_Max_Q:0.000 Epsilon:0.70 Duration:1.14 Step:946 CStep:35535\n",
            "Episode:40 Time:15:14:43 Reward:-21.00 Loss:0.00 Last_100_Avg_Rew:-20.525 Avg_Max_Q:0.000 Epsilon:0.70 Duration:1.05 Step:872 CStep:36408\n",
            "Episode:41 Time:15:14:44 Reward:-21.00 Loss:0.00 Last_100_Avg_Rew:-20.537 Avg_Max_Q:0.000 Epsilon:0.69 Duration:1.05 Step:883 CStep:37292\n",
            "Episode:42 Time:15:14:45 Reward:-20.00 Loss:0.00 Last_100_Avg_Rew:-20.524 Avg_Max_Q:0.000 Epsilon:0.68 Duration:1.04 Step:841 CStep:38134\n",
            "Episode:43 Time:15:14:46 Reward:-21.00 Loss:0.00 Last_100_Avg_Rew:-20.535 Avg_Max_Q:0.000 Epsilon:0.68 Duration:1.01 Step:823 CStep:38958\n",
            "Episode:44 Time:15:14:47 Reward:-21.00 Loss:0.00 Last_100_Avg_Rew:-20.545 Avg_Max_Q:0.000 Epsilon:0.68 Duration:1.02 Step:823 CStep:39782\n",
            "Episode:45 Time:15:15:00 Reward:-20.00 Loss:35.81 Last_100_Avg_Rew:-20.533 Avg_Max_Q:0.193 Epsilon:0.67 Duration:12.60 Step:897 CStep:40680\n",
            "Episode:46 Time:15:15:16 Reward:-21.00 Loss:4.24 Last_100_Avg_Rew:-20.543 Avg_Max_Q:0.312 Epsilon:0.66 Duration:16.18 Step:911 CStep:41592\n",
            "Episode:47 Time:15:15:29 Reward:-21.00 Loss:2.87 Last_100_Avg_Rew:-20.553 Avg_Max_Q:0.297 Epsilon:0.66 Duration:13.45 Step:763 CStep:42356\n",
            "Episode:48 Time:15:15:46 Reward:-20.00 Loss:3.02 Last_100_Avg_Rew:-20.542 Avg_Max_Q:0.261 Epsilon:0.65 Duration:17.00 Step:990 CStep:43347\n",
            "Episode:49 Time:15:16:00 Reward:-21.00 Loss:3.28 Last_100_Avg_Rew:-20.551 Avg_Max_Q:0.256 Epsilon:0.64 Duration:13.89 Step:823 CStep:44171\n",
            "Episode:50 Time:15:16:16 Reward:-20.00 Loss:2.93 Last_100_Avg_Rew:-20.540 Avg_Max_Q:0.245 Epsilon:0.64 Duration:15.38 Step:904 CStep:45076\n",
            "Episode:51 Time:15:16:33 Reward:-21.00 Loss:3.50 Last_100_Avg_Rew:-20.549 Avg_Max_Q:0.203 Epsilon:0.63 Duration:17.05 Step:979 CStep:46056\n",
            "Episode:52 Time:15:16:49 Reward:-21.00 Loss:2.25 Last_100_Avg_Rew:-20.558 Avg_Max_Q:0.208 Epsilon:0.62 Duration:16.49 Step:943 CStep:47000\n",
            "Episode:53 Time:15:17:07 Reward:-20.00 Loss:3.02 Last_100_Avg_Rew:-20.547 Avg_Max_Q:0.221 Epsilon:0.62 Duration:17.67 Step:1047 CStep:48048\n",
            "Episode:54 Time:15:17:24 Reward:-19.00 Loss:2.57 Last_100_Avg_Rew:-20.519 Avg_Max_Q:0.225 Epsilon:0.61 Duration:17.55 Step:1044 CStep:49093\n",
            "Episode:55 Time:15:17:37 Reward:-21.00 Loss:1.68 Last_100_Avg_Rew:-20.527 Avg_Max_Q:0.242 Epsilon:0.61 Duration:13.15 Step:782 CStep:49876\n",
            "Episode:56 Time:15:17:56 Reward:-20.00 Loss:2.22 Last_100_Avg_Rew:-20.518 Avg_Max_Q:0.246 Epsilon:0.61 Duration:18.53 Step:1073 CStep:50950\n",
            "Episode:57 Time:15:18:14 Reward:-19.00 Loss:2.12 Last_100_Avg_Rew:-20.491 Avg_Max_Q:0.253 Epsilon:0.59 Duration:18.10 Step:1056 CStep:52007\n",
            "Episode:58 Time:15:18:30 Reward:-21.00 Loss:1.83 Last_100_Avg_Rew:-20.500 Avg_Max_Q:0.213 Epsilon:0.59 Duration:15.92 Step:930 CStep:52938\n",
            "Episode:59 Time:15:18:47 Reward:-20.00 Loss:2.02 Last_100_Avg_Rew:-20.492 Avg_Max_Q:0.209 Epsilon:0.59 Duration:17.26 Step:975 CStep:53914\n",
            "Episode:60 Time:15:19:05 Reward:-20.00 Loss:2.12 Last_100_Avg_Rew:-20.483 Avg_Max_Q:0.197 Epsilon:0.58 Duration:17.84 Step:1045 CStep:54960\n",
            "Episode:61 Time:15:19:24 Reward:-20.00 Loss:2.35 Last_100_Avg_Rew:-20.475 Avg_Max_Q:0.192 Epsilon:0.57 Duration:18.56 Step:1074 CStep:56035\n",
            "Episode:62 Time:15:19:50 Reward:-18.00 Loss:2.50 Last_100_Avg_Rew:-20.435 Avg_Max_Q:0.111 Epsilon:0.56 Duration:26.28 Step:1550 CStep:57586\n",
            "Episode:63 Time:15:20:09 Reward:-21.00 Loss:1.76 Last_100_Avg_Rew:-20.444 Avg_Max_Q:0.016 Epsilon:0.56 Duration:19.04 Step:1120 CStep:58707\n",
            "Episode:64 Time:15:20:24 Reward:-21.00 Loss:1.29 Last_100_Avg_Rew:-20.453 Avg_Max_Q:-0.007 Epsilon:0.55 Duration:15.32 Step:891 CStep:59599\n",
            "Episode:65 Time:15:20:45 Reward:-21.00 Loss:1.41 Last_100_Avg_Rew:-20.462 Avg_Max_Q:-0.012 Epsilon:0.55 Duration:20.52 Step:1140 CStep:60740\n",
            "Episode:66 Time:15:21:07 Reward:-19.00 Loss:1.90 Last_100_Avg_Rew:-20.439 Avg_Max_Q:-0.004 Epsilon:0.54 Duration:21.92 Step:1213 CStep:61954\n",
            "Episode:67 Time:15:21:34 Reward:-18.00 Loss:2.74 Last_100_Avg_Rew:-20.403 Avg_Max_Q:-0.074 Epsilon:0.53 Duration:27.39 Step:1592 CStep:63547\n",
            "Episode:68 Time:15:22:02 Reward:-16.00 Loss:3.04 Last_100_Avg_Rew:-20.338 Avg_Max_Q:-0.068 Epsilon:0.52 Duration:28.09 Step:1576 CStep:65124\n",
            "Episode:69 Time:15:22:22 Reward:-20.00 Loss:2.18 Last_100_Avg_Rew:-20.333 Avg_Max_Q:-0.027 Epsilon:0.52 Duration:19.55 Step:1121 CStep:66246\n",
            "Episode:70 Time:15:22:43 Reward:-18.00 Loss:2.56 Last_100_Avg_Rew:-20.300 Avg_Max_Q:0.006 Epsilon:0.51 Duration:21.60 Step:1265 CStep:67512\n",
            "Episode:71 Time:15:23:05 Reward:-16.00 Loss:2.77 Last_100_Avg_Rew:-20.239 Avg_Max_Q:0.021 Epsilon:0.50 Duration:22.05 Step:1280 CStep:68793\n",
            "Episode:72 Time:15:23:26 Reward:-21.00 Loss:2.58 Last_100_Avg_Rew:-20.250 Avg_Max_Q:0.058 Epsilon:0.50 Duration:20.58 Step:1094 CStep:69888\n",
            "Episode:73 Time:15:23:49 Reward:-19.00 Loss:2.74 Last_100_Avg_Rew:-20.233 Avg_Max_Q:0.067 Epsilon:0.49 Duration:22.61 Step:1233 CStep:71122\n",
            "Episode:74 Time:15:24:12 Reward:-20.00 Loss:2.73 Last_100_Avg_Rew:-20.230 Avg_Max_Q:0.077 Epsilon:0.48 Duration:23.34 Step:1295 CStep:72418\n",
            "Episode:75 Time:15:24:33 Reward:-21.00 Loss:2.30 Last_100_Avg_Rew:-20.240 Avg_Max_Q:0.079 Epsilon:0.48 Duration:20.69 Step:1132 CStep:73551\n",
            "Episode:76 Time:15:25:01 Reward:-19.00 Loss:3.03 Last_100_Avg_Rew:-20.224 Avg_Max_Q:0.055 Epsilon:0.47 Duration:28.25 Step:1584 CStep:75136\n",
            "Episode:77 Time:15:25:20 Reward:-20.00 Loss:2.26 Last_100_Avg_Rew:-20.221 Avg_Max_Q:0.075 Epsilon:0.47 Duration:19.47 Step:1090 CStep:76227\n",
            "Episode:78 Time:15:25:42 Reward:-20.00 Loss:2.74 Last_100_Avg_Rew:-20.218 Avg_Max_Q:0.061 Epsilon:0.46 Duration:21.45 Step:1177 CStep:77405\n",
            "Episode:79 Time:15:26:07 Reward:-21.00 Loss:3.10 Last_100_Avg_Rew:-20.228 Avg_Max_Q:0.084 Epsilon:0.46 Duration:25.14 Step:1331 CStep:78737\n",
            "Episode:80 Time:15:26:31 Reward:-19.00 Loss:2.74 Last_100_Avg_Rew:-20.212 Avg_Max_Q:0.072 Epsilon:0.45 Duration:23.75 Step:1277 CStep:80015\n",
            "Episode:81 Time:15:26:53 Reward:-21.00 Loss:2.37 Last_100_Avg_Rew:-20.222 Avg_Max_Q:0.099 Epsilon:0.44 Duration:22.23 Step:1153 CStep:81169\n",
            "Episode:82 Time:15:27:15 Reward:-19.00 Loss:2.60 Last_100_Avg_Rew:-20.207 Avg_Max_Q:0.111 Epsilon:0.44 Duration:22.50 Step:1279 CStep:82449\n",
            "Episode:83 Time:15:27:39 Reward:-21.00 Loss:3.18 Last_100_Avg_Rew:-20.217 Avg_Max_Q:0.164 Epsilon:0.43 Duration:23.15 Step:1342 CStep:83792\n",
            "Episode:84 Time:15:28:10 Reward:-16.00 Loss:4.11 Last_100_Avg_Rew:-20.167 Avg_Max_Q:0.179 Epsilon:0.43 Duration:31.26 Step:1800 CStep:85593\n",
            "Episode:85 Time:15:28:39 Reward:-18.00 Loss:4.06 Last_100_Avg_Rew:-20.141 Avg_Max_Q:0.202 Epsilon:0.42 Duration:28.94 Step:1579 CStep:87173\n",
            "Episode:86 Time:15:29:11 Reward:-17.00 Loss:4.59 Last_100_Avg_Rew:-20.105 Avg_Max_Q:0.232 Epsilon:0.41 Duration:31.66 Step:1701 CStep:88875\n",
            "Episode:87 Time:15:29:37 Reward:-19.00 Loss:3.82 Last_100_Avg_Rew:-20.092 Avg_Max_Q:0.196 Epsilon:0.40 Duration:26.97 Step:1549 CStep:90425\n",
            "Episode:88 Time:15:30:07 Reward:-16.00 Loss:3.79 Last_100_Avg_Rew:-20.045 Avg_Max_Q:0.238 Epsilon:0.40 Duration:29.78 Step:1717 CStep:92143\n",
            "Episode:89 Time:15:30:27 Reward:-21.00 Loss:2.61 Last_100_Avg_Rew:-20.056 Avg_Max_Q:0.247 Epsilon:0.39 Duration:19.82 Step:1139 CStep:93283\n",
            "Episode:90 Time:15:30:50 Reward:-19.00 Loss:3.19 Last_100_Avg_Rew:-20.044 Avg_Max_Q:0.281 Epsilon:0.39 Duration:23.28 Step:1335 CStep:94619\n",
            "Episode:91 Time:15:31:16 Reward:-17.00 Loss:3.24 Last_100_Avg_Rew:-20.011 Avg_Max_Q:0.213 Epsilon:0.38 Duration:26.10 Step:1495 CStep:96115\n",
            "Episode:92 Time:15:31:48 Reward:-14.00 Loss:3.64 Last_100_Avg_Rew:-19.946 Avg_Max_Q:0.213 Epsilon:0.38 Duration:31.97 Step:1833 CStep:97949\n",
            "Episode:93 Time:15:32:11 Reward:-18.00 Loss:3.19 Last_100_Avg_Rew:-19.925 Avg_Max_Q:0.238 Epsilon:0.37 Duration:22.70 Step:1303 CStep:99253\n",
            "Episode:94 Time:15:32:30 Reward:-20.00 Loss:2.80 Last_100_Avg_Rew:-19.926 Avg_Max_Q:0.262 Epsilon:0.37 Duration:18.83 Step:1087 CStep:100341\n",
            "Episode:95 Time:15:32:57 Reward:-19.00 Loss:3.79 Last_100_Avg_Rew:-19.916 Avg_Max_Q:0.232 Epsilon:0.36 Duration:26.61 Step:1549 CStep:101891\n",
            "Episode:96 Time:15:33:22 Reward:-19.00 Loss:3.37 Last_100_Avg_Rew:-19.906 Avg_Max_Q:0.265 Epsilon:0.36 Duration:25.31 Step:1431 CStep:103323\n",
            "Episode:97 Time:15:33:53 Reward:-15.00 Loss:3.67 Last_100_Avg_Rew:-19.856 Avg_Max_Q:0.269 Epsilon:0.35 Duration:31.03 Step:1786 CStep:105110\n",
            "Episode:98 Time:15:34:19 Reward:-17.00 Loss:3.04 Last_100_Avg_Rew:-19.827 Avg_Max_Q:0.262 Epsilon:0.34 Duration:25.65 Step:1477 CStep:106588\n",
            "Episode:99 Time:15:34:50 Reward:-17.00 Loss:4.04 Last_100_Avg_Rew:-19.798 Avg_Max_Q:0.276 Epsilon:0.34 Duration:31.71 Step:1834 CStep:108423\n",
            "Episode:100 Time:15:35:21 Reward:-14.00 Loss:3.55 Last_100_Avg_Rew:-19.740 Avg_Max_Q:0.278 Epsilon:0.33 Duration:30.71 Step:1710 CStep:110134\n",
            "Episode:101 Time:15:35:44 Reward:-19.00 Loss:2.83 Last_100_Avg_Rew:-19.740 Avg_Max_Q:0.352 Epsilon:0.33 Duration:22.98 Step:1326 CStep:111461\n",
            "Episode:102 Time:15:36:15 Reward:-18.00 Loss:3.63 Last_100_Avg_Rew:-19.720 Avg_Max_Q:0.364 Epsilon:0.32 Duration:31.38 Step:1813 CStep:113275\n",
            "Episode:103 Time:15:36:43 Reward:-17.00 Loss:3.54 Last_100_Avg_Rew:-19.680 Avg_Max_Q:0.381 Epsilon:0.32 Duration:27.49 Step:1586 CStep:114862\n",
            "Episode:104 Time:15:37:15 Reward:-17.00 Loss:3.80 Last_100_Avg_Rew:-19.660 Avg_Max_Q:0.312 Epsilon:0.31 Duration:32.03 Step:1856 CStep:116719\n",
            "Episode:105 Time:15:37:43 Reward:-21.00 Loss:2.98 Last_100_Avg_Rew:-19.670 Avg_Max_Q:0.316 Epsilon:0.31 Duration:28.19 Step:1563 CStep:118283\n",
            "Episode:106 Time:15:38:06 Reward:-20.00 Loss:2.94 Last_100_Avg_Rew:-19.660 Avg_Max_Q:0.286 Epsilon:0.30 Duration:23.09 Step:1303 CStep:119587\n",
            "Episode:107 Time:15:38:37 Reward:-19.00 Loss:3.58 Last_100_Avg_Rew:-19.650 Avg_Max_Q:0.360 Epsilon:0.30 Duration:31.20 Step:1748 CStep:121336\n",
            "Episode:108 Time:15:39:09 Reward:-15.00 Loss:3.34 Last_100_Avg_Rew:-19.590 Avg_Max_Q:0.355 Epsilon:0.29 Duration:31.25 Step:1764 CStep:123101\n",
            "Episode:109 Time:15:39:43 Reward:-17.00 Loss:3.76 Last_100_Avg_Rew:-19.560 Avg_Max_Q:0.382 Epsilon:0.29 Duration:34.47 Step:1896 CStep:124998\n",
            "Episode:110 Time:15:40:18 Reward:-20.00 Loss:3.99 Last_100_Avg_Rew:-19.550 Avg_Max_Q:0.453 Epsilon:0.28 Duration:34.69 Step:1846 CStep:126845\n",
            "Episode:111 Time:15:40:55 Reward:-16.00 Loss:4.25 Last_100_Avg_Rew:-19.510 Avg_Max_Q:0.466 Epsilon:0.28 Duration:37.38 Step:2047 CStep:128893\n",
            "Episode:112 Time:15:41:20 Reward:-20.00 Loss:3.23 Last_100_Avg_Rew:-19.500 Avg_Max_Q:0.455 Epsilon:0.27 Duration:25.07 Step:1427 CStep:130321\n",
            "Episode:113 Time:15:41:54 Reward:-20.00 Loss:4.29 Last_100_Avg_Rew:-19.490 Avg_Max_Q:0.477 Epsilon:0.27 Duration:34.08 Step:1973 CStep:132295\n",
            "Episode:114 Time:15:42:29 Reward:-15.00 Loss:4.36 Last_100_Avg_Rew:-19.440 Avg_Max_Q:0.474 Epsilon:0.26 Duration:35.06 Step:2014 CStep:134310\n",
            "Episode:115 Time:15:43:04 Reward:-18.00 Loss:4.58 Last_100_Avg_Rew:-19.410 Avg_Max_Q:0.453 Epsilon:0.25 Duration:34.65 Step:1968 CStep:136279\n",
            "Episode:116 Time:15:43:41 Reward:-16.00 Loss:4.36 Last_100_Avg_Rew:-19.370 Avg_Max_Q:0.450 Epsilon:0.25 Duration:36.83 Step:2121 CStep:138401\n",
            "Episode:117 Time:15:44:14 Reward:-17.00 Loss:3.95 Last_100_Avg_Rew:-19.340 Avg_Max_Q:0.526 Epsilon:0.24 Duration:33.22 Step:1930 CStep:140332\n",
            "Episode:118 Time:15:44:51 Reward:-17.00 Loss:4.20 Last_100_Avg_Rew:-19.310 Avg_Max_Q:0.497 Epsilon:0.24 Duration:36.69 Step:1982 CStep:142315\n",
            "Episode:119 Time:15:45:20 Reward:-18.00 Loss:3.15 Last_100_Avg_Rew:-19.280 Avg_Max_Q:0.514 Epsilon:0.24 Duration:29.60 Step:1591 CStep:143907\n",
            "Episode:120 Time:15:45:52 Reward:-14.00 Loss:3.93 Last_100_Avg_Rew:-19.210 Avg_Max_Q:0.563 Epsilon:0.23 Duration:31.12 Step:1808 CStep:145716\n",
            "Episode:121 Time:15:46:25 Reward:-19.00 Loss:4.07 Last_100_Avg_Rew:-19.190 Avg_Max_Q:0.569 Epsilon:0.23 Duration:33.07 Step:1909 CStep:147626\n",
            "Episode:122 Time:15:46:50 Reward:-20.00 Loss:3.65 Last_100_Avg_Rew:-19.180 Avg_Max_Q:0.343 Epsilon:0.22 Duration:25.11 Step:1455 CStep:149082\n",
            "Episode:123 Time:15:47:16 Reward:-18.00 Loss:2.80 Last_100_Avg_Rew:-19.150 Avg_Max_Q:0.417 Epsilon:0.22 Duration:26.07 Step:1509 CStep:150592\n",
            "Episode:124 Time:15:47:45 Reward:-20.00 Loss:2.93 Last_100_Avg_Rew:-19.140 Avg_Max_Q:0.427 Epsilon:0.22 Duration:29.18 Step:1647 CStep:152240\n",
            "Episode:125 Time:15:48:23 Reward:-16.00 Loss:3.48 Last_100_Avg_Rew:-19.100 Avg_Max_Q:0.439 Epsilon:0.21 Duration:38.10 Step:2201 CStep:154442\n",
            "Episode:126 Time:15:48:52 Reward:-16.00 Loss:3.43 Last_100_Avg_Rew:-19.060 Avg_Max_Q:0.489 Epsilon:0.21 Duration:29.18 Step:1689 CStep:156132\n",
            "Episode:127 Time:15:49:22 Reward:-19.00 Loss:3.62 Last_100_Avg_Rew:-19.050 Avg_Max_Q:0.563 Epsilon:0.21 Duration:29.25 Step:1697 CStep:157830\n",
            "Episode:128 Time:15:50:02 Reward:-15.00 Loss:4.98 Last_100_Avg_Rew:-18.990 Avg_Max_Q:0.580 Epsilon:0.20 Duration:40.67 Step:2352 CStep:160183\n",
            "Episode:129 Time:15:50:41 Reward:-18.00 Loss:5.30 Last_100_Avg_Rew:-18.980 Avg_Max_Q:0.597 Epsilon:0.20 Duration:39.02 Step:2270 CStep:162454\n",
            "Episode:130 Time:15:51:16 Reward:-15.00 Loss:4.54 Last_100_Avg_Rew:-18.920 Avg_Max_Q:0.603 Epsilon:0.19 Duration:34.42 Step:1988 CStep:164443\n",
            "Episode:131 Time:15:51:53 Reward:-17.00 Loss:4.37 Last_100_Avg_Rew:-18.880 Avg_Max_Q:0.568 Epsilon:0.19 Duration:37.53 Step:2165 CStep:166609\n",
            "Episode:132 Time:15:52:30 Reward:-17.00 Loss:4.83 Last_100_Avg_Rew:-18.850 Avg_Max_Q:0.580 Epsilon:0.18 Duration:37.26 Step:2106 CStep:168716\n",
            "Episode:133 Time:15:53:16 Reward:-11.00 Loss:5.98 Last_100_Avg_Rew:-18.750 Avg_Max_Q:0.619 Epsilon:0.18 Duration:45.35 Step:2571 CStep:171288\n",
            "Episode:134 Time:15:53:57 Reward:-16.00 Loss:5.10 Last_100_Avg_Rew:-18.700 Avg_Max_Q:0.666 Epsilon:0.18 Duration:40.78 Step:2244 CStep:173533\n",
            "Episode:135 Time:15:54:33 Reward:-15.00 Loss:4.53 Last_100_Avg_Rew:-18.640 Avg_Max_Q:0.679 Epsilon:0.17 Duration:36.92 Step:2099 CStep:175633\n",
            "Episode:136 Time:15:55:10 Reward:-17.00 Loss:4.80 Last_100_Avg_Rew:-18.600 Avg_Max_Q:0.678 Epsilon:0.17 Duration:36.69 Step:2097 CStep:177731\n",
            "Episode:137 Time:15:55:45 Reward:-19.00 Loss:4.83 Last_100_Avg_Rew:-18.580 Avg_Max_Q:0.687 Epsilon:0.17 Duration:35.09 Step:2009 CStep:179741\n",
            "Episode:138 Time:15:56:15 Reward:-17.00 Loss:3.88 Last_100_Avg_Rew:-18.540 Avg_Max_Q:0.645 Epsilon:0.16 Duration:29.76 Step:1704 CStep:181446\n",
            "Episode:139 Time:15:56:52 Reward:-18.00 Loss:3.73 Last_100_Avg_Rew:-18.510 Avg_Max_Q:0.623 Epsilon:0.16 Duration:36.91 Step:2015 CStep:183462\n",
            "Episode:140 Time:15:57:30 Reward:-13.00 Loss:3.77 Last_100_Avg_Rew:-18.430 Avg_Max_Q:0.603 Epsilon:0.16 Duration:38.01 Step:2145 CStep:185608\n",
            "Episode:141 Time:15:58:04 Reward:-18.00 Loss:3.88 Last_100_Avg_Rew:-18.400 Avg_Max_Q:0.650 Epsilon:0.15 Duration:34.18 Step:1931 CStep:187540\n",
            "Episode:142 Time:15:58:46 Reward:-13.00 Loss:4.38 Last_100_Avg_Rew:-18.330 Avg_Max_Q:0.610 Epsilon:0.15 Duration:42.08 Step:2370 CStep:189911\n",
            "Episode:143 Time:15:59:21 Reward:-17.00 Loss:3.77 Last_100_Avg_Rew:-18.290 Avg_Max_Q:0.641 Epsilon:0.15 Duration:34.98 Step:1983 CStep:191895\n",
            "Episode:144 Time:16:00:07 Reward:-12.00 Loss:4.49 Last_100_Avg_Rew:-18.200 Avg_Max_Q:0.609 Epsilon:0.14 Duration:45.93 Step:2583 CStep:194479\n",
            "Episode:145 Time:16:00:42 Reward:-19.00 Loss:3.88 Last_100_Avg_Rew:-18.190 Avg_Max_Q:0.596 Epsilon:0.14 Duration:35.25 Step:1919 CStep:196399\n",
            "Episode:146 Time:16:01:17 Reward:-19.00 Loss:4.05 Last_100_Avg_Rew:-18.170 Avg_Max_Q:0.640 Epsilon:0.14 Duration:34.36 Step:1928 CStep:198328\n",
            "Episode:147 Time:16:02:01 Reward:-19.00 Loss:4.43 Last_100_Avg_Rew:-18.150 Avg_Max_Q:0.667 Epsilon:0.13 Duration:44.03 Step:2434 CStep:200763\n",
            "Episode:148 Time:16:02:49 Reward:-15.00 Loss:5.40 Last_100_Avg_Rew:-18.100 Avg_Max_Q:0.680 Epsilon:0.13 Duration:47.80 Step:2670 CStep:203434\n",
            "Episode:149 Time:16:03:30 Reward:-18.00 Loss:5.02 Last_100_Avg_Rew:-18.070 Avg_Max_Q:0.696 Epsilon:0.13 Duration:41.38 Step:2273 CStep:205708\n",
            "Episode:150 Time:16:03:58 Reward:-20.00 Loss:3.71 Last_100_Avg_Rew:-18.070 Avg_Max_Q:0.587 Epsilon:0.12 Duration:28.41 Step:1592 CStep:207301\n",
            "Episode:151 Time:16:04:30 Reward:-18.00 Loss:3.44 Last_100_Avg_Rew:-18.040 Avg_Max_Q:0.614 Epsilon:0.12 Duration:31.68 Step:1789 CStep:209091\n",
            "Episode:152 Time:16:05:03 Reward:-18.00 Loss:3.01 Last_100_Avg_Rew:-18.010 Avg_Max_Q:0.582 Epsilon:0.12 Duration:33.12 Step:1858 CStep:210950\n",
            "Episode:153 Time:16:05:44 Reward:-14.00 Loss:4.06 Last_100_Avg_Rew:-17.950 Avg_Max_Q:0.594 Epsilon:0.12 Duration:41.05 Step:2321 CStep:213272\n",
            "Episode:154 Time:16:06:24 Reward:-17.00 Loss:3.85 Last_100_Avg_Rew:-17.930 Avg_Max_Q:0.595 Epsilon:0.12 Duration:39.39 Step:2188 CStep:215461\n",
            "Episode:155 Time:16:07:07 Reward:-14.00 Loss:3.95 Last_100_Avg_Rew:-17.860 Avg_Max_Q:0.617 Epsilon:0.11 Duration:43.68 Step:2395 CStep:217857\n",
            "Episode:156 Time:16:07:43 Reward:-17.00 Loss:3.43 Last_100_Avg_Rew:-17.830 Avg_Max_Q:0.645 Epsilon:0.11 Duration:36.09 Step:2056 CStep:219914\n",
            "Episode:157 Time:16:08:11 Reward:-16.00 Loss:2.89 Last_100_Avg_Rew:-17.800 Avg_Max_Q:0.661 Epsilon:0.11 Duration:27.50 Step:1577 CStep:221492\n",
            "Episode:158 Time:16:08:44 Reward:-16.00 Loss:3.38 Last_100_Avg_Rew:-17.750 Avg_Max_Q:0.684 Epsilon:0.11 Duration:32.70 Step:1863 CStep:223356\n",
            "Episode:159 Time:16:09:14 Reward:-18.00 Loss:4.05 Last_100_Avg_Rew:-17.730 Avg_Max_Q:0.720 Epsilon:0.10 Duration:30.76 Step:1773 CStep:225130\n",
            "Episode:160 Time:16:09:50 Reward:-16.00 Loss:4.09 Last_100_Avg_Rew:-17.690 Avg_Max_Q:0.710 Epsilon:0.10 Duration:36.00 Step:2085 CStep:227216\n",
            "Episode:161 Time:16:10:30 Reward:-17.00 Loss:4.24 Last_100_Avg_Rew:-17.660 Avg_Max_Q:0.703 Epsilon:0.10 Duration:39.99 Step:2258 CStep:229475\n",
            "Episode:162 Time:16:11:05 Reward:-17.00 Loss:3.83 Last_100_Avg_Rew:-17.650 Avg_Max_Q:0.702 Epsilon:0.10 Duration:34.81 Step:2012 CStep:231488\n",
            "Episode:163 Time:16:11:42 Reward:-17.00 Loss:4.08 Last_100_Avg_Rew:-17.610 Avg_Max_Q:0.726 Epsilon:0.10 Duration:37.29 Step:2081 CStep:233570\n",
            "Episode:164 Time:16:12:18 Reward:-17.00 Loss:4.00 Last_100_Avg_Rew:-17.570 Avg_Max_Q:0.697 Epsilon:0.09 Duration:35.13 Step:1920 CStep:235491\n",
            "Episode:165 Time:16:12:51 Reward:-18.00 Loss:3.76 Last_100_Avg_Rew:-17.540 Avg_Max_Q:0.726 Epsilon:0.09 Duration:33.76 Step:1931 CStep:237423\n",
            "Episode:166 Time:16:13:31 Reward:-15.00 Loss:4.11 Last_100_Avg_Rew:-17.500 Avg_Max_Q:0.711 Epsilon:0.09 Duration:39.89 Step:2152 CStep:239576\n",
            "Episode:167 Time:16:14:11 Reward:-15.00 Loss:3.91 Last_100_Avg_Rew:-17.470 Avg_Max_Q:0.671 Epsilon:0.09 Duration:40.15 Step:2104 CStep:241681\n",
            "Episode:168 Time:16:14:48 Reward:-17.00 Loss:3.86 Last_100_Avg_Rew:-17.480 Avg_Max_Q:0.679 Epsilon:0.09 Duration:37.03 Step:1937 CStep:243619\n",
            "Episode:169 Time:16:15:14 Reward:-21.00 Loss:2.81 Last_100_Avg_Rew:-17.490 Avg_Max_Q:0.632 Epsilon:0.09 Duration:25.25 Step:1413 CStep:245033\n",
            "Episode:170 Time:16:15:52 Reward:-16.00 Loss:4.20 Last_100_Avg_Rew:-17.470 Avg_Max_Q:0.666 Epsilon:0.08 Duration:38.00 Step:2151 CStep:247185\n",
            "Episode:171 Time:16:16:30 Reward:-14.00 Loss:4.48 Last_100_Avg_Rew:-17.450 Avg_Max_Q:0.719 Epsilon:0.08 Duration:38.19 Step:2137 CStep:249323\n",
            "Episode:172 Time:16:17:05 Reward:-15.00 Loss:4.75 Last_100_Avg_Rew:-17.390 Avg_Max_Q:0.770 Epsilon:0.08 Duration:35.05 Step:1956 CStep:251280\n",
            "Episode:173 Time:16:17:48 Reward:-15.00 Loss:5.70 Last_100_Avg_Rew:-17.350 Avg_Max_Q:0.777 Epsilon:0.08 Duration:42.61 Step:2420 CStep:253701\n",
            "Episode:174 Time:16:18:34 Reward:-13.00 Loss:6.06 Last_100_Avg_Rew:-17.280 Avg_Max_Q:0.788 Epsilon:0.08 Duration:46.33 Step:2607 CStep:256309\n",
            "Episode:175 Time:16:19:09 Reward:-17.00 Loss:4.64 Last_100_Avg_Rew:-17.240 Avg_Max_Q:0.788 Epsilon:0.07 Duration:35.41 Step:1932 CStep:258242\n",
            "Episode:176 Time:16:19:54 Reward:-13.00 Loss:5.47 Last_100_Avg_Rew:-17.180 Avg_Max_Q:0.816 Epsilon:0.07 Duration:44.89 Step:2462 CStep:260705\n",
            "Episode:177 Time:16:20:30 Reward:-18.00 Loss:4.26 Last_100_Avg_Rew:-17.160 Avg_Max_Q:0.815 Epsilon:0.07 Duration:35.54 Step:1932 CStep:262638\n",
            "Episode:178 Time:16:21:09 Reward:-14.00 Loss:5.15 Last_100_Avg_Rew:-17.100 Avg_Max_Q:0.797 Epsilon:0.07 Duration:39.36 Step:2157 CStep:264796\n",
            "Episode:179 Time:16:21:42 Reward:-17.00 Loss:4.40 Last_100_Avg_Rew:-17.060 Avg_Max_Q:0.816 Epsilon:0.07 Duration:32.82 Step:1851 CStep:266648\n",
            "Episode:180 Time:16:22:31 Reward:-11.00 Loss:6.09 Last_100_Avg_Rew:-16.980 Avg_Max_Q:0.812 Epsilon:0.07 Duration:49.39 Step:2756 CStep:269405\n",
            "Episode:181 Time:16:23:05 Reward:-17.00 Loss:5.69 Last_100_Avg_Rew:-16.940 Avg_Max_Q:0.864 Epsilon:0.07 Duration:33.89 Step:1883 CStep:271289\n",
            "Episode:182 Time:16:23:46 Reward:-15.00 Loss:6.51 Last_100_Avg_Rew:-16.900 Avg_Max_Q:0.870 Epsilon:0.06 Duration:41.24 Step:2141 CStep:273431\n",
            "Episode:183 Time:16:24:34 Reward:-10.00 Loss:6.44 Last_100_Avg_Rew:-16.790 Avg_Max_Q:0.841 Epsilon:0.06 Duration:47.87 Step:2455 CStep:275887\n",
            "Episode:184 Time:16:25:12 Reward:-14.00 Loss:4.87 Last_100_Avg_Rew:-16.770 Avg_Max_Q:0.828 Epsilon:0.06 Duration:37.24 Step:1940 CStep:277828\n",
            "Episode:185 Time:16:25:58 Reward:-11.00 Loss:5.79 Last_100_Avg_Rew:-16.700 Avg_Max_Q:0.833 Epsilon:0.06 Duration:46.76 Step:2491 CStep:280320\n",
            "Episode:186 Time:16:26:34 Reward:-14.00 Loss:4.82 Last_100_Avg_Rew:-16.670 Avg_Max_Q:0.846 Epsilon:0.06 Duration:35.31 Step:1952 CStep:282273\n",
            "Episode:187 Time:16:27:04 Reward:-16.00 Loss:3.91 Last_100_Avg_Rew:-16.640 Avg_Max_Q:0.829 Epsilon:0.06 Duration:29.98 Step:1693 CStep:283967\n",
            "Episode:188 Time:16:27:43 Reward:-11.00 Loss:5.17 Last_100_Avg_Rew:-16.590 Avg_Max_Q:0.864 Epsilon:0.06 Duration:38.86 Step:2201 CStep:286169\n",
            "Episode:189 Time:16:28:28 Reward:-16.00 Loss:6.15 Last_100_Avg_Rew:-16.540 Avg_Max_Q:0.941 Epsilon:0.06 Duration:45.28 Step:2514 CStep:288684\n",
            "Episode:190 Time:16:29:07 Reward:-12.00 Loss:6.20 Last_100_Avg_Rew:-16.470 Avg_Max_Q:0.980 Epsilon:0.05 Duration:39.65 Step:2220 CStep:290905\n",
            "Episode:191 Time:16:29:46 Reward:-14.00 Loss:5.67 Last_100_Avg_Rew:-16.440 Avg_Max_Q:0.938 Epsilon:0.05 Duration:38.87 Step:2205 CStep:293111\n",
            "Episode:192 Time:16:30:31 Reward:-11.00 Loss:6.24 Last_100_Avg_Rew:-16.410 Avg_Max_Q:0.967 Epsilon:0.05 Duration:44.47 Step:2432 CStep:295544\n",
            "Episode:193 Time:16:31:15 Reward:-11.00 Loss:5.67 Last_100_Avg_Rew:-16.340 Avg_Max_Q:0.924 Epsilon:0.05 Duration:44.47 Step:2490 CStep:298035\n",
            "Episode:194 Time:16:31:56 Reward:-15.00 Loss:5.76 Last_100_Avg_Rew:-16.290 Avg_Max_Q:0.964 Epsilon:0.05 Duration:40.87 Step:2215 CStep:300251\n",
            "Episode:195 Time:16:32:41 Reward:-11.00 Loss:5.75 Last_100_Avg_Rew:-16.210 Avg_Max_Q:0.977 Epsilon:0.05 Duration:44.79 Step:2403 CStep:302655\n",
            "Episode:196 Time:16:33:25 Reward:-16.00 Loss:6.34 Last_100_Avg_Rew:-16.180 Avg_Max_Q:0.970 Epsilon:0.05 Duration:43.98 Step:2390 CStep:305046\n",
            "Episode:197 Time:16:34:03 Reward:-13.00 Loss:5.82 Last_100_Avg_Rew:-16.160 Avg_Max_Q:0.968 Epsilon:0.05 Duration:38.33 Step:2172 CStep:307219\n",
            "Episode:198 Time:16:34:49 Reward:-11.00 Loss:7.07 Last_100_Avg_Rew:-16.100 Avg_Max_Q:0.967 Epsilon:0.05 Duration:45.77 Step:2580 CStep:309800\n",
            "Episode:199 Time:16:35:40 Reward:-8.00 Loss:7.00 Last_100_Avg_Rew:-16.010 Avg_Max_Q:0.972 Epsilon:0.05 Duration:51.18 Step:2795 CStep:312596\n",
            "Episode:200 Time:16:36:25 Reward:-12.00 Loss:6.33 Last_100_Avg_Rew:-15.990 Avg_Max_Q:0.970 Epsilon:0.05 Duration:45.19 Step:2480 CStep:315077\n",
            "Episode:201 Time:16:37:00 Reward:-13.00 Loss:5.42 Last_100_Avg_Rew:-15.930 Avg_Max_Q:1.001 Epsilon:0.05 Duration:34.61 Step:1894 CStep:316972\n",
            "Episode:202 Time:16:37:41 Reward:-10.00 Loss:5.83 Last_100_Avg_Rew:-15.850 Avg_Max_Q:0.992 Epsilon:0.05 Duration:41.26 Step:2251 CStep:319224\n",
            "Episode:203 Time:16:38:19 Reward:-13.00 Loss:4.86 Last_100_Avg_Rew:-15.810 Avg_Max_Q:0.994 Epsilon:0.05 Duration:37.82 Step:2022 CStep:321247\n",
            "Episode:204 Time:16:39:12 Reward:-6.00 Loss:6.14 Last_100_Avg_Rew:-15.700 Avg_Max_Q:0.967 Epsilon:0.05 Duration:53.21 Step:2893 CStep:324141\n",
            "Episode:205 Time:16:39:48 Reward:-14.00 Loss:4.95 Last_100_Avg_Rew:-15.630 Avg_Max_Q:0.968 Epsilon:0.05 Duration:36.18 Step:1965 CStep:326107\n",
            "Episode:206 Time:16:40:44 Reward:-8.00 Loss:6.37 Last_100_Avg_Rew:-15.510 Avg_Max_Q:0.994 Epsilon:0.05 Duration:55.74 Step:3017 CStep:329125\n",
            "Episode:207 Time:16:41:37 Reward:-6.00 Loss:5.59 Last_100_Avg_Rew:-15.380 Avg_Max_Q:0.990 Epsilon:0.05 Duration:53.02 Step:2818 CStep:331944\n",
            "Episode:208 Time:16:42:23 Reward:-9.00 Loss:5.68 Last_100_Avg_Rew:-15.320 Avg_Max_Q:1.019 Epsilon:0.05 Duration:45.38 Step:2471 CStep:334416\n",
            "Episode:209 Time:16:43:21 Reward:-4.00 Loss:6.46 Last_100_Avg_Rew:-15.190 Avg_Max_Q:0.996 Epsilon:0.05 Duration:58.50 Step:3133 CStep:337550\n",
            "Episode:210 Time:16:44:22 Reward:-3.00 Loss:7.26 Last_100_Avg_Rew:-15.020 Avg_Max_Q:0.998 Epsilon:0.05 Duration:60.65 Step:3321 CStep:340872\n",
            "Episode:211 Time:16:45:12 Reward:-4.00 Loss:6.50 Last_100_Avg_Rew:-14.900 Avg_Max_Q:1.014 Epsilon:0.05 Duration:49.79 Step:2864 CStep:343737\n",
            "Episode:212 Time:16:45:40 Reward:-15.00 Loss:4.30 Last_100_Avg_Rew:-14.850 Avg_Max_Q:1.032 Epsilon:0.05 Duration:28.36 Step:1644 CStep:345382\n",
            "Episode:213 Time:16:46:37 Reward:-5.00 Loss:6.55 Last_100_Avg_Rew:-14.700 Avg_Max_Q:1.030 Epsilon:0.05 Duration:57.53 Step:3055 CStep:348438\n",
            "Episode:214 Time:16:47:35 Reward:-1.00 Loss:6.71 Last_100_Avg_Rew:-14.560 Avg_Max_Q:1.043 Epsilon:0.05 Duration:57.70 Step:3143 CStep:351582\n",
            "Episode:215 Time:16:48:29 Reward:6.00 Loss:6.90 Last_100_Avg_Rew:-14.320 Avg_Max_Q:1.064 Epsilon:0.05 Duration:53.61 Step:2941 CStep:354524\n",
            "Episode:216 Time:16:49:08 Reward:-7.00 Loss:5.84 Last_100_Avg_Rew:-14.230 Avg_Max_Q:1.045 Epsilon:0.05 Duration:39.55 Step:2286 CStep:356811\n",
            "Episode:217 Time:16:50:00 Reward:1.00 Loss:7.05 Last_100_Avg_Rew:-14.050 Avg_Max_Q:1.050 Epsilon:0.05 Duration:51.63 Step:2963 CStep:359775\n",
            "Episode:218 Time:16:50:50 Reward:-4.00 Loss:6.01 Last_100_Avg_Rew:-13.920 Avg_Max_Q:1.030 Epsilon:0.05 Duration:49.70 Step:2707 CStep:362483\n",
            "Episode:219 Time:16:51:33 Reward:7.00 Loss:5.13 Last_100_Avg_Rew:-13.670 Avg_Max_Q:1.031 Epsilon:0.05 Duration:43.45 Step:2484 CStep:364968\n",
            "Episode:220 Time:16:52:11 Reward:14.00 Loss:4.79 Last_100_Avg_Rew:-13.390 Avg_Max_Q:1.026 Epsilon:0.05 Duration:37.93 Step:2176 CStep:367145\n",
            "Episode:221 Time:16:52:59 Reward:11.00 Loss:5.23 Last_100_Avg_Rew:-13.090 Avg_Max_Q:1.021 Epsilon:0.05 Duration:47.76 Step:2751 CStep:369897\n",
            "Episode:222 Time:16:53:41 Reward:8.00 Loss:4.36 Last_100_Avg_Rew:-12.810 Avg_Max_Q:1.004 Epsilon:0.05 Duration:42.38 Step:2440 CStep:372338\n",
            "Episode:223 Time:16:54:20 Reward:11.00 Loss:4.32 Last_100_Avg_Rew:-12.520 Avg_Max_Q:1.039 Epsilon:0.05 Duration:39.10 Step:2241 CStep:374580\n",
            "Episode:224 Time:16:55:12 Reward:-3.00 Loss:5.47 Last_100_Avg_Rew:-12.350 Avg_Max_Q:1.050 Epsilon:0.05 Duration:52.12 Step:2990 CStep:377571\n",
            "Episode:225 Time:16:55:51 Reward:13.00 Loss:5.28 Last_100_Avg_Rew:-12.060 Avg_Max_Q:1.092 Epsilon:0.05 Duration:38.75 Step:2245 CStep:379817\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ve4vYDe3bozg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b43131c6-c3cd-4661-faa1-c3614c79166b"
      },
      "source": [
        "environment = gym.make(ENVIRONMENT,  render_mode='rgb_array')  # Get env\n",
        "agent = Agent(environment)  # Create Agent\n",
        "\n",
        "if LOAD_MODEL_FROM_FILE:\n",
        "    agent.online_model.load_state_dict(torch.load(MODEL_PATH+str(LOAD_FILE_EPISODE)+\".pkl\"))\n",
        "\n",
        "    with open(MODEL_PATH+str(LOAD_FILE_EPISODE)+'.json') as outfile:\n",
        "        param = json.load(outfile)\n",
        "        agent.epsilon = param.get('epsilon')\n",
        "\n",
        "    startEpisode = LOAD_FILE_EPISODE + 1\n",
        "\n",
        "else:\n",
        "    startEpisode = 1\n",
        "\n",
        "last_100_ep_reward = deque(maxlen=100)  # Last 100 episode rewards\n",
        "total_step = 1  # Cumulkative sum of all steps in episodes\n",
        "for episode in range(startEpisode, MAX_EPISODE):\n",
        "\n",
        "    startTime = time.time()  # Keep time\n",
        "    state = environment.reset()  # Reset env\n",
        "    state= environment.render()\n",
        "\n",
        "    state = agent.preProcess(state)  # Process image\n",
        "\n",
        "    # Stack state . Every state contains 4 time contionusly frames\n",
        "    # We stack frames like 4 channel image\n",
        "    state = np.stack((state, state, state, state))\n",
        "\n",
        "    total_max_q_val = 0  # Total max q vals\n",
        "    total_reward = 0  # Total reward for each episode\n",
        "    total_loss = 0  # Total loss for each episode\n",
        "    for step in range(MAX_STEP):\n",
        "\n",
        "        if RENDER_GAME_WINDOW:\n",
        "            environment.render()  # Show state visually\n",
        "\n",
        "        # Select and perform an action\n",
        "        action = agent.act(state)  # Act\n",
        "        next_state, reward, done,_,  info = environment.step(action)  # Observe\n",
        "\n",
        "        next_state = agent.preProcess(next_state)  # Process image\n",
        "\n",
        "        # Stack state . Every state contains 4 time contionusly frames\n",
        "        # We stack frames like 4 channel image\n",
        "        next_state = np.stack((next_state, state[0], state[1], state[2]))\n",
        "\n",
        "        # Store the transition in memory\n",
        "        agent.storeResults(state, action, reward, next_state, done)  # Store to mem\n",
        "\n",
        "        # Move to the next state\n",
        "        state = next_state  # Update state\n",
        "\n",
        "        if TRAIN_MODEL:\n",
        "            # Perform one step of the optimization (on the target network)\n",
        "            loss, max_q_val = agent.train()  # Train with random BATCH_SIZE state taken from mem\n",
        "        else:\n",
        "            loss, max_q_val = [0, 0]\n",
        "\n",
        "        total_loss += loss\n",
        "        total_max_q_val += max_q_val\n",
        "        total_reward += reward\n",
        "        total_step += 1\n",
        "        if total_step % 1000 == 0:\n",
        "            agent.adaptiveEpsilon()  # Decrase epsilon\n",
        "\n",
        "        if done:  # Episode completed\n",
        "            currentTime = time.time()  # Keep current time\n",
        "            time_passed = currentTime - startTime  # Find episode duration\n",
        "            current_time_format = time.strftime(\"%H:%M:%S\", time.gmtime())  # Get current dateTime as HH:MM:SS\n",
        "            epsilonDict = {'epsilon': agent.epsilon}  # Create epsilon dict to save model as file\n",
        "\n",
        "            if SAVE_MODELS and episode % SAVE_MODEL_INTERVAL == 0:  # Save model as file\n",
        "                weightsPath = MODEL_PATH + str(episode) + '.pkl'\n",
        "                epsilonPath = MODEL_PATH + str(episode) + '.json'\n",
        "\n",
        "                torch.save(agent.online_model.state_dict(), weightsPath)\n",
        "                with open(epsilonPath, 'w') as outfile:\n",
        "                    json.dump(epsilonDict, outfile)\n",
        "\n",
        "            if TRAIN_MODEL:\n",
        "                agent.target_model.load_state_dict(agent.online_model.state_dict())  # Update target model\n",
        "\n",
        "            last_100_ep_reward.append(total_reward)\n",
        "            avg_max_q_val = total_max_q_val / step\n",
        "\n",
        "            outStr = \"Episode:{} Time:{} Reward:{:.2f} Loss:{:.2f} Last_100_Avg_Rew:{:.3f} Avg_Max_Q:{:.3f} Epsilon:{:.2f} Duration:{:.2f} Step:{} CStep:{}\".format(\n",
        "                episode, current_time_format, total_reward, total_loss, np.mean(last_100_ep_reward), avg_max_q_val, agent.epsilon, time_passed, step, total_step\n",
        "            )\n",
        "\n",
        "            print(outStr)\n",
        "\n",
        "            if SAVE_MODELS:\n",
        "                outputPath = MODEL_PATH + \"out\" + '.txt'  # Save outStr to file\n",
        "                with open(outputPath, 'a') as outfile:\n",
        "                    outfile.write(outStr+\"\\n\")\n",
        "\n",
        "            break\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/gym/utils/passive_env_checker.py:289: UserWarning: \u001b[33mWARN: No render fps was declared in the environment (env.metadata['render_fps'] is None or not defined), rendering may occur at inconsistent fps.\u001b[0m\n",
            "  logger.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Episode:1 Time:09:09:34 Reward:-20.00 Loss:0.00 Last_100_Avg_Rew:-20.000 Avg_Max_Q:0.000 Epsilon:1.00 Duration:0.72 Step:963 CStep:965\n",
            "Episode:2 Time:09:09:41 Reward:-21.00 Loss:0.00 Last_100_Avg_Rew:-20.500 Avg_Max_Q:0.000 Epsilon:0.99 Duration:7.25 Step:823 CStep:1789\n",
            "Episode:3 Time:09:09:42 Reward:-21.00 Loss:0.00 Last_100_Avg_Rew:-20.667 Avg_Max_Q:0.000 Epsilon:0.98 Duration:0.68 Step:904 CStep:2694\n",
            "Episode:4 Time:09:09:43 Reward:-21.00 Loss:0.00 Last_100_Avg_Rew:-20.750 Avg_Max_Q:0.000 Epsilon:0.97 Duration:0.62 Step:823 CStep:3518\n",
            "Episode:5 Time:09:09:44 Reward:-19.00 Loss:0.00 Last_100_Avg_Rew:-20.400 Avg_Max_Q:0.000 Epsilon:0.96 Duration:0.81 Step:1007 CStep:4526\n",
            "Episode:6 Time:09:09:44 Reward:-21.00 Loss:0.00 Last_100_Avg_Rew:-20.500 Avg_Max_Q:0.000 Epsilon:0.95 Duration:0.69 Step:851 CStep:5378\n",
            "Episode:7 Time:09:09:45 Reward:-21.00 Loss:0.00 Last_100_Avg_Rew:-20.571 Avg_Max_Q:0.000 Epsilon:0.94 Duration:0.70 Step:841 CStep:6220\n",
            "Episode:8 Time:09:09:46 Reward:-21.00 Loss:0.00 Last_100_Avg_Rew:-20.625 Avg_Max_Q:0.000 Epsilon:0.93 Duration:0.82 Step:823 CStep:7044\n",
            "Episode:9 Time:09:09:47 Reward:-21.00 Loss:0.00 Last_100_Avg_Rew:-20.667 Avg_Max_Q:0.000 Epsilon:0.93 Duration:0.80 Step:763 CStep:7808\n",
            "Episode:10 Time:09:09:47 Reward:-20.00 Loss:0.00 Last_100_Avg_Rew:-20.600 Avg_Max_Q:0.000 Epsilon:0.92 Duration:0.89 Step:1007 CStep:8816\n",
            "Episode:11 Time:09:09:49 Reward:-21.00 Loss:0.00 Last_100_Avg_Rew:-20.636 Avg_Max_Q:0.000 Epsilon:0.91 Duration:1.25 Step:1006 CStep:9823\n",
            "Episode:12 Time:09:09:50 Reward:-21.00 Loss:0.00 Last_100_Avg_Rew:-20.667 Avg_Max_Q:0.000 Epsilon:0.90 Duration:1.03 Step:763 CStep:10587\n",
            "Episode:13 Time:09:09:51 Reward:-20.00 Loss:0.00 Last_100_Avg_Rew:-20.615 Avg_Max_Q:0.000 Epsilon:0.90 Duration:1.01 Step:946 CStep:11534\n",
            "Episode:14 Time:09:09:52 Reward:-20.00 Loss:0.00 Last_100_Avg_Rew:-20.571 Avg_Max_Q:0.000 Epsilon:0.89 Duration:0.82 Step:873 CStep:12408\n",
            "Episode:15 Time:09:09:52 Reward:-21.00 Loss:0.00 Last_100_Avg_Rew:-20.600 Avg_Max_Q:0.000 Epsilon:0.88 Duration:0.69 Step:763 CStep:13172\n",
            "Episode:16 Time:09:09:53 Reward:-21.00 Loss:0.00 Last_100_Avg_Rew:-20.625 Avg_Max_Q:0.000 Epsilon:0.88 Duration:0.72 Step:824 CStep:13997\n",
            "Episode:17 Time:09:09:54 Reward:-19.00 Loss:0.00 Last_100_Avg_Rew:-20.529 Avg_Max_Q:0.000 Epsilon:0.87 Duration:0.89 Step:914 CStep:14912\n",
            "Episode:18 Time:09:09:55 Reward:-21.00 Loss:0.00 Last_100_Avg_Rew:-20.556 Avg_Max_Q:0.000 Epsilon:0.86 Duration:0.75 Step:811 CStep:15724\n",
            "Episode:19 Time:09:09:55 Reward:-21.00 Loss:0.00 Last_100_Avg_Rew:-20.579 Avg_Max_Q:0.000 Epsilon:0.85 Duration:0.71 Step:763 CStep:16488\n",
            "Episode:20 Time:09:09:56 Reward:-21.00 Loss:0.00 Last_100_Avg_Rew:-20.600 Avg_Max_Q:0.000 Epsilon:0.84 Duration:0.70 Step:763 CStep:17252\n",
            "Episode:21 Time:09:09:57 Reward:-21.00 Loss:0.00 Last_100_Avg_Rew:-20.619 Avg_Max_Q:0.000 Epsilon:0.83 Duration:0.82 Step:842 CStep:18095\n",
            "Episode:22 Time:09:09:58 Reward:-21.00 Loss:0.00 Last_100_Avg_Rew:-20.636 Avg_Max_Q:0.000 Epsilon:0.83 Duration:0.74 Step:763 CStep:18859\n",
            "Episode:23 Time:09:09:58 Reward:-21.00 Loss:0.00 Last_100_Avg_Rew:-20.652 Avg_Max_Q:0.000 Epsilon:0.83 Duration:0.75 Step:763 CStep:19623\n",
            "Episode:24 Time:09:09:59 Reward:-21.00 Loss:0.00 Last_100_Avg_Rew:-20.667 Avg_Max_Q:0.000 Epsilon:0.82 Duration:0.77 Step:763 CStep:20387\n",
            "Episode:25 Time:09:10:00 Reward:-21.00 Loss:0.00 Last_100_Avg_Rew:-20.680 Avg_Max_Q:0.000 Epsilon:0.81 Duration:0.75 Step:763 CStep:21151\n",
            "Episode:26 Time:09:10:01 Reward:-21.00 Loss:0.00 Last_100_Avg_Rew:-20.692 Avg_Max_Q:0.000 Epsilon:0.81 Duration:0.98 Step:763 CStep:21915\n",
            "Episode:27 Time:09:10:02 Reward:-21.00 Loss:0.00 Last_100_Avg_Rew:-20.704 Avg_Max_Q:0.000 Epsilon:0.80 Duration:1.24 Step:763 CStep:22679\n",
            "Episode:28 Time:09:10:03 Reward:-21.00 Loss:0.00 Last_100_Avg_Rew:-20.714 Avg_Max_Q:0.000 Epsilon:0.79 Duration:1.15 Step:763 CStep:23443\n",
            "Episode:29 Time:09:10:04 Reward:-21.00 Loss:0.00 Last_100_Avg_Rew:-20.724 Avg_Max_Q:0.000 Epsilon:0.79 Duration:0.87 Step:763 CStep:24207\n",
            "Episode:30 Time:09:10:05 Reward:-21.00 Loss:0.00 Last_100_Avg_Rew:-20.733 Avg_Max_Q:0.000 Epsilon:0.79 Duration:0.83 Step:763 CStep:24971\n",
            "Episode:31 Time:09:10:06 Reward:-21.00 Loss:0.00 Last_100_Avg_Rew:-20.742 Avg_Max_Q:0.000 Epsilon:0.78 Duration:0.81 Step:763 CStep:25735\n",
            "Episode:32 Time:09:10:07 Reward:-21.00 Loss:0.00 Last_100_Avg_Rew:-20.750 Avg_Max_Q:0.000 Epsilon:0.77 Duration:0.78 Step:763 CStep:26499\n",
            "Episode:33 Time:09:10:07 Reward:-21.00 Loss:0.00 Last_100_Avg_Rew:-20.758 Avg_Max_Q:0.000 Epsilon:0.76 Duration:0.90 Step:825 CStep:27325\n",
            "Episode:34 Time:09:10:08 Reward:-21.00 Loss:0.00 Last_100_Avg_Rew:-20.765 Avg_Max_Q:0.000 Epsilon:0.75 Duration:0.81 Step:763 CStep:28089\n",
            "Episode:35 Time:09:10:09 Reward:-21.00 Loss:0.00 Last_100_Avg_Rew:-20.771 Avg_Max_Q:0.000 Epsilon:0.75 Duration:0.81 Step:763 CStep:28853\n",
            "Episode:36 Time:09:10:10 Reward:-21.00 Loss:0.00 Last_100_Avg_Rew:-20.778 Avg_Max_Q:0.000 Epsilon:0.75 Duration:0.78 Step:763 CStep:29617\n",
            "Episode:37 Time:09:10:11 Reward:-21.00 Loss:0.00 Last_100_Avg_Rew:-20.784 Avg_Max_Q:0.000 Epsilon:0.74 Duration:0.84 Step:763 CStep:30381\n",
            "Episode:38 Time:09:10:12 Reward:-21.00 Loss:0.00 Last_100_Avg_Rew:-20.789 Avg_Max_Q:0.000 Epsilon:0.73 Duration:0.82 Step:763 CStep:31145\n",
            "Episode:39 Time:09:10:12 Reward:-21.00 Loss:0.00 Last_100_Avg_Rew:-20.795 Avg_Max_Q:0.000 Epsilon:0.73 Duration:0.84 Step:763 CStep:31909\n",
            "Episode:40 Time:09:10:13 Reward:-21.00 Loss:0.00 Last_100_Avg_Rew:-20.800 Avg_Max_Q:0.000 Epsilon:0.72 Duration:0.85 Step:763 CStep:32673\n",
            "Episode:41 Time:09:10:14 Reward:-21.00 Loss:0.00 Last_100_Avg_Rew:-20.805 Avg_Max_Q:0.000 Epsilon:0.72 Duration:1.12 Step:763 CStep:33437\n",
            "Episode:42 Time:09:10:16 Reward:-21.00 Loss:0.00 Last_100_Avg_Rew:-20.810 Avg_Max_Q:0.000 Epsilon:0.71 Duration:1.21 Step:763 CStep:34201\n",
            "Episode:43 Time:09:10:17 Reward:-21.00 Loss:0.00 Last_100_Avg_Rew:-20.814 Avg_Max_Q:0.000 Epsilon:0.71 Duration:1.09 Step:763 CStep:34965\n",
            "Episode:44 Time:09:10:18 Reward:-21.00 Loss:0.00 Last_100_Avg_Rew:-20.818 Avg_Max_Q:0.000 Epsilon:0.70 Duration:0.89 Step:811 CStep:35777\n",
            "Episode:45 Time:09:10:18 Reward:-21.00 Loss:0.00 Last_100_Avg_Rew:-20.822 Avg_Max_Q:0.000 Epsilon:0.70 Duration:0.80 Step:763 CStep:36541\n",
            "Episode:46 Time:09:10:19 Reward:-21.00 Loss:0.00 Last_100_Avg_Rew:-20.826 Avg_Max_Q:0.000 Epsilon:0.69 Duration:0.86 Step:763 CStep:37305\n",
            "Episode:47 Time:09:10:20 Reward:-21.00 Loss:0.00 Last_100_Avg_Rew:-20.830 Avg_Max_Q:0.000 Epsilon:0.68 Duration:0.86 Step:763 CStep:38069\n",
            "Episode:48 Time:09:10:21 Reward:-21.00 Loss:0.00 Last_100_Avg_Rew:-20.833 Avg_Max_Q:0.000 Epsilon:0.68 Duration:0.88 Step:763 CStep:38833\n",
            "Episode:49 Time:09:10:22 Reward:-21.00 Loss:0.00 Last_100_Avg_Rew:-20.837 Avg_Max_Q:0.000 Epsilon:0.68 Duration:0.88 Step:763 CStep:39597\n",
            "Episode:50 Time:09:10:32 Reward:-20.00 Loss:11.83 Last_100_Avg_Rew:-20.820 Avg_Max_Q:0.106 Epsilon:0.67 Duration:9.73 Step:841 CStep:40439\n",
            "Episode:51 Time:09:10:49 Reward:-21.00 Loss:4.25 Last_100_Avg_Rew:-20.824 Avg_Max_Q:0.070 Epsilon:0.66 Duration:17.13 Step:957 CStep:41397\n",
            "Episode:52 Time:09:11:06 Reward:-20.00 Loss:2.32 Last_100_Avg_Rew:-20.808 Avg_Max_Q:0.046 Epsilon:0.66 Duration:17.36 Step:950 CStep:42348\n",
            "Episode:53 Time:09:11:21 Reward:-21.00 Loss:1.85 Last_100_Avg_Rew:-20.811 Avg_Max_Q:0.034 Epsilon:0.65 Duration:14.93 Step:791 CStep:43140\n",
            "Episode:54 Time:09:11:35 Reward:-21.00 Loss:1.45 Last_100_Avg_Rew:-20.815 Avg_Max_Q:0.041 Epsilon:0.65 Duration:14.10 Step:782 CStep:43923\n",
            "Episode:55 Time:09:11:53 Reward:-19.00 Loss:1.44 Last_100_Avg_Rew:-20.782 Avg_Max_Q:0.028 Epsilon:0.64 Duration:18.10 Step:1048 CStep:44972\n",
            "Episode:56 Time:09:12:07 Reward:-21.00 Loss:1.81 Last_100_Avg_Rew:-20.786 Avg_Max_Q:0.023 Epsilon:0.64 Duration:13.92 Step:825 CStep:45798\n",
            "Episode:57 Time:09:12:21 Reward:-20.00 Loss:1.91 Last_100_Avg_Rew:-20.772 Avg_Max_Q:0.035 Epsilon:0.63 Duration:14.21 Step:843 CStep:46642\n",
            "Episode:58 Time:09:12:38 Reward:-20.00 Loss:1.77 Last_100_Avg_Rew:-20.759 Avg_Max_Q:0.042 Epsilon:0.62 Duration:17.06 Step:919 CStep:47562\n",
            "Episode:59 Time:09:12:53 Reward:-21.00 Loss:1.51 Last_100_Avg_Rew:-20.763 Avg_Max_Q:0.064 Epsilon:0.62 Duration:14.64 Step:874 CStep:48437\n",
            "Episode:60 Time:09:13:07 Reward:-21.00 Loss:2.09 Last_100_Avg_Rew:-20.767 Avg_Max_Q:0.090 Epsilon:0.61 Duration:14.01 Step:823 CStep:49261\n",
            "Episode:61 Time:09:13:22 Reward:-20.00 Loss:1.76 Last_100_Avg_Rew:-20.754 Avg_Max_Q:0.098 Epsilon:0.61 Duration:15.08 Step:897 CStep:50159\n",
            "Episode:62 Time:09:13:38 Reward:-20.00 Loss:1.96 Last_100_Avg_Rew:-20.742 Avg_Max_Q:0.103 Epsilon:0.60 Duration:15.57 Step:920 CStep:51080\n",
            "Episode:63 Time:09:13:57 Reward:-19.00 Loss:1.89 Last_100_Avg_Rew:-20.714 Avg_Max_Q:0.105 Epsilon:0.59 Duration:19.73 Step:1160 CStep:52241\n",
            "Episode:64 Time:09:14:14 Reward:-19.00 Loss:1.81 Last_100_Avg_Rew:-20.688 Avg_Max_Q:0.129 Epsilon:0.59 Duration:16.33 Step:975 CStep:53217\n",
            "Episode:65 Time:09:14:29 Reward:-20.00 Loss:1.93 Last_100_Avg_Rew:-20.677 Avg_Max_Q:0.154 Epsilon:0.58 Duration:15.05 Step:901 CStep:54119\n",
            "Episode:66 Time:09:14:42 Reward:-21.00 Loss:1.47 Last_100_Avg_Rew:-20.682 Avg_Max_Q:0.145 Epsilon:0.58 Duration:13.54 Step:782 CStep:54902\n",
            "Episode:67 Time:09:14:55 Reward:-21.00 Loss:1.46 Last_100_Avg_Rew:-20.687 Avg_Max_Q:0.152 Epsilon:0.58 Duration:13.00 Step:763 CStep:55666\n",
            "Episode:68 Time:09:15:13 Reward:-20.00 Loss:1.81 Last_100_Avg_Rew:-20.676 Avg_Max_Q:0.154 Epsilon:0.57 Duration:17.99 Step:1035 CStep:56702\n",
            "Episode:69 Time:09:15:32 Reward:-19.00 Loss:1.69 Last_100_Avg_Rew:-20.652 Avg_Max_Q:0.126 Epsilon:0.56 Duration:18.75 Step:1115 CStep:57818\n",
            "Episode:70 Time:09:15:52 Reward:-19.00 Loss:1.47 Last_100_Avg_Rew:-20.629 Avg_Max_Q:0.126 Epsilon:0.56 Duration:19.89 Step:1155 CStep:58974\n",
            "Episode:71 Time:09:16:14 Reward:-19.00 Loss:1.73 Last_100_Avg_Rew:-20.606 Avg_Max_Q:0.133 Epsilon:0.55 Duration:21.95 Step:1262 CStep:60237\n",
            "Episode:72 Time:09:16:39 Reward:-20.00 Loss:1.92 Last_100_Avg_Rew:-20.597 Avg_Max_Q:0.137 Epsilon:0.54 Duration:24.84 Step:1417 CStep:61655\n",
            "Episode:73 Time:09:16:56 Reward:-21.00 Loss:1.47 Last_100_Avg_Rew:-20.603 Avg_Max_Q:0.124 Epsilon:0.54 Duration:17.16 Step:995 CStep:62651\n",
            "Episode:74 Time:09:17:18 Reward:-20.00 Loss:2.01 Last_100_Avg_Rew:-20.595 Avg_Max_Q:0.129 Epsilon:0.53 Duration:22.17 Step:1308 CStep:63960\n",
            "Episode:75 Time:09:17:35 Reward:-21.00 Loss:1.24 Last_100_Avg_Rew:-20.600 Avg_Max_Q:0.096 Epsilon:0.53 Duration:16.92 Step:991 CStep:64952\n",
            "Episode:76 Time:09:17:53 Reward:-20.00 Loss:1.39 Last_100_Avg_Rew:-20.592 Avg_Max_Q:0.114 Epsilon:0.52 Duration:17.71 Step:1034 CStep:65987\n",
            "Episode:77 Time:09:18:10 Reward:-21.00 Loss:1.12 Last_100_Avg_Rew:-20.597 Avg_Max_Q:0.088 Epsilon:0.52 Duration:17.10 Step:989 CStep:66977\n",
            "Episode:78 Time:09:18:29 Reward:-20.00 Loss:1.32 Last_100_Avg_Rew:-20.590 Avg_Max_Q:0.095 Epsilon:0.50 Duration:19.12 Step:1144 CStep:68122\n",
            "Episode:79 Time:09:18:52 Reward:-18.00 Loss:1.73 Last_100_Avg_Rew:-20.557 Avg_Max_Q:0.099 Epsilon:0.50 Duration:22.89 Step:1299 CStep:69422\n",
            "Episode:80 Time:09:19:10 Reward:-21.00 Loss:1.40 Last_100_Avg_Rew:-20.562 Avg_Max_Q:0.085 Epsilon:0.49 Duration:17.76 Step:1000 CStep:70423\n",
            "Episode:81 Time:09:19:33 Reward:-19.00 Loss:1.99 Last_100_Avg_Rew:-20.543 Avg_Max_Q:0.106 Epsilon:0.49 Duration:23.05 Step:1348 CStep:71772\n",
            "Episode:82 Time:09:19:56 Reward:-18.00 Loss:2.07 Last_100_Avg_Rew:-20.512 Avg_Max_Q:0.137 Epsilon:0.48 Duration:23.15 Step:1361 CStep:73134\n",
            "Episode:83 Time:09:20:15 Reward:-20.00 Loss:1.67 Last_100_Avg_Rew:-20.506 Avg_Max_Q:0.154 Epsilon:0.48 Duration:19.44 Step:1145 CStep:74280\n",
            "Episode:84 Time:09:20:37 Reward:-18.00 Loss:2.09 Last_100_Avg_Rew:-20.476 Avg_Max_Q:0.182 Epsilon:0.47 Duration:22.03 Step:1255 CStep:75536\n",
            "Episode:85 Time:09:21:06 Reward:-18.00 Loss:2.26 Last_100_Avg_Rew:-20.447 Avg_Max_Q:0.189 Epsilon:0.46 Duration:29.04 Step:1688 CStep:77225\n",
            "Episode:86 Time:09:21:29 Reward:-19.00 Loss:2.21 Last_100_Avg_Rew:-20.430 Avg_Max_Q:0.229 Epsilon:0.46 Duration:22.41 Step:1313 CStep:78539\n",
            "Episode:87 Time:09:21:52 Reward:-20.00 Loss:1.99 Last_100_Avg_Rew:-20.425 Avg_Max_Q:0.206 Epsilon:0.45 Duration:23.53 Step:1374 CStep:79914\n",
            "Episode:88 Time:09:22:14 Reward:-19.00 Loss:2.20 Last_100_Avg_Rew:-20.409 Avg_Max_Q:0.182 Epsilon:0.44 Duration:21.48 Step:1249 CStep:81164\n",
            "Episode:89 Time:09:22:38 Reward:-19.00 Loss:2.50 Last_100_Avg_Rew:-20.393 Avg_Max_Q:0.169 Epsilon:0.44 Duration:23.85 Step:1396 CStep:82561\n",
            "Episode:90 Time:09:23:00 Reward:-18.00 Loss:2.46 Last_100_Avg_Rew:-20.367 Avg_Max_Q:0.153 Epsilon:0.43 Duration:22.40 Step:1336 CStep:83898\n",
            "Episode:91 Time:09:23:24 Reward:-17.00 Loss:2.65 Last_100_Avg_Rew:-20.330 Avg_Max_Q:0.202 Epsilon:0.43 Duration:23.41 Step:1373 CStep:85272\n",
            "Episode:92 Time:09:23:55 Reward:-19.00 Loss:3.27 Last_100_Avg_Rew:-20.315 Avg_Max_Q:0.262 Epsilon:0.42 Duration:31.58 Step:1852 CStep:87125\n",
            "Episode:93 Time:09:24:16 Reward:-19.00 Loss:2.80 Last_100_Avg_Rew:-20.301 Avg_Max_Q:0.282 Epsilon:0.41 Duration:21.16 Step:1270 CStep:88396\n",
            "Episode:94 Time:09:24:43 Reward:-18.00 Loss:3.15 Last_100_Avg_Rew:-20.277 Avg_Max_Q:0.312 Epsilon:0.41 Duration:26.51 Step:1524 CStep:89921\n",
            "Episode:95 Time:09:25:11 Reward:-16.00 Loss:3.60 Last_100_Avg_Rew:-20.232 Avg_Max_Q:0.350 Epsilon:0.40 Duration:28.71 Step:1624 CStep:91546\n",
            "Episode:96 Time:09:25:35 Reward:-17.00 Loss:3.35 Last_100_Avg_Rew:-20.198 Avg_Max_Q:0.382 Epsilon:0.40 Duration:23.89 Step:1415 CStep:92962\n",
            "Episode:97 Time:09:26:01 Reward:-19.00 Loss:3.26 Last_100_Avg_Rew:-20.186 Avg_Max_Q:0.415 Epsilon:0.39 Duration:25.65 Step:1490 CStep:94453\n",
            "Episode:98 Time:09:26:34 Reward:-12.00 Loss:3.74 Last_100_Avg_Rew:-20.102 Avg_Max_Q:0.462 Epsilon:0.38 Duration:32.79 Step:1900 CStep:96354\n",
            "Episode:99 Time:09:27:03 Reward:-17.00 Loss:3.81 Last_100_Avg_Rew:-20.071 Avg_Max_Q:0.440 Epsilon:0.37 Duration:29.07 Step:1704 CStep:98059\n",
            "Episode:100 Time:09:27:33 Reward:-17.00 Loss:4.26 Last_100_Avg_Rew:-20.040 Avg_Max_Q:0.445 Epsilon:0.37 Duration:29.94 Step:1725 CStep:99785\n",
            "Episode:101 Time:09:28:05 Reward:-17.00 Loss:4.23 Last_100_Avg_Rew:-20.010 Avg_Max_Q:0.453 Epsilon:0.36 Duration:32.37 Step:1910 CStep:101696\n",
            "Episode:102 Time:09:28:30 Reward:-20.00 Loss:3.16 Last_100_Avg_Rew:-20.000 Avg_Max_Q:0.371 Epsilon:0.36 Duration:24.31 Step:1417 CStep:103114\n",
            "Episode:103 Time:09:28:48 Reward:-21.00 Loss:2.49 Last_100_Avg_Rew:-20.000 Avg_Max_Q:0.369 Epsilon:0.35 Duration:18.69 Step:1077 CStep:104192\n",
            "Episode:104 Time:09:29:16 Reward:-19.00 Loss:3.54 Last_100_Avg_Rew:-19.980 Avg_Max_Q:0.424 Epsilon:0.35 Duration:28.21 Step:1607 CStep:105800\n",
            "Episode:105 Time:09:29:52 Reward:-17.00 Loss:4.39 Last_100_Avg_Rew:-19.960 Avg_Max_Q:0.433 Epsilon:0.34 Duration:35.74 Step:2107 CStep:107908\n",
            "Episode:106 Time:09:30:16 Reward:-20.00 Loss:3.49 Last_100_Avg_Rew:-19.950 Avg_Max_Q:0.422 Epsilon:0.33 Duration:23.59 Step:1400 CStep:109309\n",
            "Episode:107 Time:09:30:45 Reward:-16.00 Loss:3.59 Last_100_Avg_Rew:-19.900 Avg_Max_Q:0.381 Epsilon:0.33 Duration:29.20 Step:1687 CStep:110997\n",
            "Episode:108 Time:09:31:12 Reward:-19.00 Loss:3.40 Last_100_Avg_Rew:-19.880 Avg_Max_Q:0.453 Epsilon:0.32 Duration:26.95 Step:1566 CStep:112564\n",
            "Episode:109 Time:09:31:36 Reward:-19.00 Loss:3.42 Last_100_Avg_Rew:-19.860 Avg_Max_Q:0.481 Epsilon:0.32 Duration:23.89 Step:1399 CStep:113964\n",
            "Episode:110 Time:09:32:08 Reward:-16.00 Loss:4.49 Last_100_Avg_Rew:-19.820 Avg_Max_Q:0.546 Epsilon:0.31 Duration:32.21 Step:1910 CStep:115875\n",
            "Episode:111 Time:09:32:32 Reward:-20.00 Loss:3.35 Last_100_Avg_Rew:-19.810 Avg_Max_Q:0.552 Epsilon:0.31 Duration:24.04 Step:1397 CStep:117273\n",
            "Episode:112 Time:09:33:05 Reward:-16.00 Loss:4.09 Last_100_Avg_Rew:-19.760 Avg_Max_Q:0.505 Epsilon:0.30 Duration:32.59 Step:1830 CStep:119104\n",
            "Episode:113 Time:09:33:33 Reward:-20.00 Loss:3.46 Last_100_Avg_Rew:-19.760 Avg_Max_Q:0.528 Epsilon:0.30 Duration:27.92 Step:1627 CStep:120732\n",
            "Episode:114 Time:09:34:09 Reward:-15.00 Loss:4.11 Last_100_Avg_Rew:-19.710 Avg_Max_Q:0.518 Epsilon:0.29 Duration:36.50 Step:2145 CStep:122878\n",
            "Episode:115 Time:09:34:39 Reward:-19.00 Loss:3.75 Last_100_Avg_Rew:-19.690 Avg_Max_Q:0.528 Epsilon:0.29 Duration:30.27 Step:1778 CStep:124657\n",
            "Episode:116 Time:09:35:05 Reward:-18.00 Loss:3.36 Last_100_Avg_Rew:-19.660 Avg_Max_Q:0.528 Epsilon:0.28 Duration:25.53 Step:1499 CStep:126157\n",
            "Episode:117 Time:09:35:31 Reward:-20.00 Loss:3.33 Last_100_Avg_Rew:-19.670 Avg_Max_Q:0.533 Epsilon:0.28 Duration:26.00 Step:1523 CStep:127681\n",
            "Episode:118 Time:09:36:00 Reward:-20.00 Loss:3.49 Last_100_Avg_Rew:-19.660 Avg_Max_Q:0.575 Epsilon:0.27 Duration:29.36 Step:1724 CStep:129406\n",
            "Episode:119 Time:09:36:27 Reward:-16.00 Loss:3.41 Last_100_Avg_Rew:-19.610 Avg_Max_Q:0.532 Epsilon:0.27 Duration:27.09 Step:1581 CStep:130988\n",
            "Episode:120 Time:09:36:52 Reward:-20.00 Loss:2.80 Last_100_Avg_Rew:-19.600 Avg_Max_Q:0.520 Epsilon:0.27 Duration:24.24 Step:1409 CStep:132398\n",
            "Episode:121 Time:09:37:31 Reward:-9.00 Loss:3.68 Last_100_Avg_Rew:-19.480 Avg_Max_Q:0.546 Epsilon:0.26 Duration:39.60 Step:2281 CStep:134680\n",
            "Episode:122 Time:09:37:59 Reward:-17.00 Loss:3.13 Last_100_Avg_Rew:-19.440 Avg_Max_Q:0.555 Epsilon:0.25 Duration:27.37 Step:1590 CStep:136271\n",
            "Episode:123 Time:09:38:30 Reward:-15.00 Loss:3.66 Last_100_Avg_Rew:-19.380 Avg_Max_Q:0.630 Epsilon:0.25 Duration:31.28 Step:1835 CStep:138107\n",
            "Episode:124 Time:09:38:56 Reward:-17.00 Loss:3.16 Last_100_Avg_Rew:-19.340 Avg_Max_Q:0.587 Epsilon:0.25 Duration:26.26 Step:1543 CStep:139651\n",
            "Episode:125 Time:09:39:18 Reward:-20.00 Loss:3.05 Last_100_Avg_Rew:-19.330 Avg_Max_Q:0.621 Epsilon:0.24 Duration:22.31 Step:1288 CStep:140940\n",
            "Episode:126 Time:09:39:52 Reward:-14.00 Loss:4.23 Last_100_Avg_Rew:-19.260 Avg_Max_Q:0.641 Epsilon:0.24 Duration:33.35 Step:1961 CStep:142902\n",
            "Episode:127 Time:09:40:24 Reward:-19.00 Loss:4.18 Last_100_Avg_Rew:-19.240 Avg_Max_Q:0.706 Epsilon:0.24 Duration:32.61 Step:1899 CStep:144802\n",
            "Episode:128 Time:09:40:59 Reward:-16.00 Loss:3.92 Last_100_Avg_Rew:-19.190 Avg_Max_Q:0.682 Epsilon:0.23 Duration:34.29 Step:1941 CStep:146744\n",
            "Episode:129 Time:09:41:31 Reward:-18.00 Loss:3.96 Last_100_Avg_Rew:-19.160 Avg_Max_Q:0.735 Epsilon:0.23 Duration:31.86 Step:1860 CStep:148605\n",
            "Episode:130 Time:09:42:03 Reward:-16.00 Loss:3.54 Last_100_Avg_Rew:-19.110 Avg_Max_Q:0.709 Epsilon:0.22 Duration:32.43 Step:1884 CStep:150490\n",
            "Episode:131 Time:09:42:29 Reward:-19.00 Loss:3.42 Last_100_Avg_Rew:-19.090 Avg_Max_Q:0.730 Epsilon:0.22 Duration:25.79 Step:1505 CStep:151996\n",
            "Episode:132 Time:09:42:57 Reward:-16.00 Loss:3.59 Last_100_Avg_Rew:-19.040 Avg_Max_Q:0.664 Epsilon:0.21 Duration:28.53 Step:1679 CStep:153676\n",
            "Episode:133 Time:09:43:34 Reward:-13.00 Loss:4.89 Last_100_Avg_Rew:-18.960 Avg_Max_Q:0.702 Epsilon:0.21 Duration:36.44 Step:2132 CStep:155809\n",
            "Episode:134 Time:09:44:13 Reward:-10.00 Loss:5.46 Last_100_Avg_Rew:-18.850 Avg_Max_Q:0.693 Epsilon:0.20 Duration:39.66 Step:2327 CStep:158137\n",
            "Episode:135 Time:09:44:34 Reward:-20.00 Loss:2.85 Last_100_Avg_Rew:-18.840 Avg_Max_Q:0.687 Epsilon:0.20 Duration:20.32 Step:1177 CStep:159315\n",
            "Episode:136 Time:09:45:07 Reward:-16.00 Loss:4.11 Last_100_Avg_Rew:-18.790 Avg_Max_Q:0.735 Epsilon:0.20 Duration:33.41 Step:1883 CStep:161199\n",
            "Episode:137 Time:09:45:37 Reward:-16.00 Loss:3.57 Last_100_Avg_Rew:-18.740 Avg_Max_Q:0.760 Epsilon:0.20 Duration:29.62 Step:1741 CStep:162941\n",
            "Episode:138 Time:09:46:00 Reward:-20.00 Loss:2.84 Last_100_Avg_Rew:-18.730 Avg_Max_Q:0.777 Epsilon:0.19 Duration:23.36 Step:1365 CStep:164307\n",
            "Episode:139 Time:09:46:24 Reward:-20.00 Loss:2.80 Last_100_Avg_Rew:-18.720 Avg_Max_Q:0.791 Epsilon:0.19 Duration:23.68 Step:1364 CStep:165672\n",
            "Episode:140 Time:09:46:55 Reward:-17.00 Loss:3.34 Last_100_Avg_Rew:-18.680 Avg_Max_Q:0.775 Epsilon:0.19 Duration:31.07 Step:1795 CStep:167468\n",
            "Episode:141 Time:09:47:28 Reward:-16.00 Loss:4.05 Last_100_Avg_Rew:-18.630 Avg_Max_Q:0.803 Epsilon:0.18 Duration:33.22 Step:1954 CStep:169423\n",
            "Episode:142 Time:09:47:58 Reward:-17.00 Loss:3.70 Last_100_Avg_Rew:-18.590 Avg_Max_Q:0.744 Epsilon:0.18 Duration:29.89 Step:1748 CStep:171172\n",
            "Episode:143 Time:09:48:27 Reward:-17.00 Loss:4.00 Last_100_Avg_Rew:-18.550 Avg_Max_Q:0.839 Epsilon:0.18 Duration:29.44 Step:1716 CStep:172889\n",
            "Episode:144 Time:09:48:53 Reward:-20.00 Loss:3.59 Last_100_Avg_Rew:-18.540 Avg_Max_Q:0.855 Epsilon:0.17 Duration:25.10 Step:1430 CStep:174320\n",
            "Episode:145 Time:09:49:18 Reward:-20.00 Loss:4.15 Last_100_Avg_Rew:-18.530 Avg_Max_Q:0.863 Epsilon:0.17 Duration:25.07 Step:1459 CStep:175780\n",
            "Episode:146 Time:09:49:48 Reward:-16.00 Loss:4.69 Last_100_Avg_Rew:-18.480 Avg_Max_Q:0.845 Epsilon:0.17 Duration:29.90 Step:1767 CStep:177548\n",
            "Episode:147 Time:09:50:23 Reward:-16.00 Loss:5.28 Last_100_Avg_Rew:-18.430 Avg_Max_Q:0.843 Epsilon:0.17 Duration:35.26 Step:2046 CStep:179595\n",
            "Episode:148 Time:09:51:01 Reward:-12.00 Loss:4.91 Last_100_Avg_Rew:-18.340 Avg_Max_Q:0.791 Epsilon:0.16 Duration:37.90 Step:2218 CStep:181814\n",
            "Episode:149 Time:09:51:35 Reward:-17.00 Loss:4.66 Last_100_Avg_Rew:-18.300 Avg_Max_Q:0.825 Epsilon:0.16 Duration:34.79 Step:2019 CStep:183834\n",
            "Episode:150 Time:09:52:10 Reward:-13.00 Loss:5.21 Last_100_Avg_Rew:-18.230 Avg_Max_Q:0.796 Epsilon:0.16 Duration:34.51 Step:2042 CStep:185877\n",
            "Episode:151 Time:09:52:46 Reward:-16.00 Loss:4.85 Last_100_Avg_Rew:-18.180 Avg_Max_Q:0.783 Epsilon:0.15 Duration:36.26 Step:2060 CStep:187938\n",
            "Episode:152 Time:09:53:20 Reward:-12.00 Loss:4.26 Last_100_Avg_Rew:-18.100 Avg_Max_Q:0.778 Epsilon:0.15 Duration:33.79 Step:1953 CStep:189892\n",
            "Episode:153 Time:09:53:58 Reward:-10.00 Loss:4.87 Last_100_Avg_Rew:-17.990 Avg_Max_Q:0.799 Epsilon:0.15 Duration:37.98 Step:2222 CStep:192115\n",
            "Episode:154 Time:09:54:25 Reward:-17.00 Loss:3.79 Last_100_Avg_Rew:-17.950 Avg_Max_Q:0.809 Epsilon:0.14 Duration:27.42 Step:1603 CStep:193719\n",
            "Episode:155 Time:09:54:56 Reward:-15.00 Loss:4.13 Last_100_Avg_Rew:-17.910 Avg_Max_Q:0.815 Epsilon:0.14 Duration:30.80 Step:1814 CStep:195534\n",
            "Episode:156 Time:09:55:30 Reward:-13.00 Loss:3.75 Last_100_Avg_Rew:-17.830 Avg_Max_Q:0.756 Epsilon:0.14 Duration:33.77 Step:1957 CStep:197492\n",
            "Episode:157 Time:09:56:01 Reward:-16.00 Loss:3.90 Last_100_Avg_Rew:-17.790 Avg_Max_Q:0.736 Epsilon:0.14 Duration:31.02 Step:1823 CStep:199316\n",
            "Episode:158 Time:09:56:42 Reward:-11.00 Loss:4.30 Last_100_Avg_Rew:-17.700 Avg_Max_Q:0.708 Epsilon:0.13 Duration:40.81 Step:2333 CStep:201650\n",
            "Episode:159 Time:09:57:14 Reward:-14.00 Loss:3.46 Last_100_Avg_Rew:-17.630 Avg_Max_Q:0.703 Epsilon:0.13 Duration:32.53 Step:1907 CStep:203558\n",
            "Episode:160 Time:09:57:56 Reward:-13.00 Loss:4.50 Last_100_Avg_Rew:-17.550 Avg_Max_Q:0.726 Epsilon:0.13 Duration:41.64 Step:2442 CStep:206001\n",
            "Episode:161 Time:09:58:40 Reward:-11.00 Loss:4.47 Last_100_Avg_Rew:-17.460 Avg_Max_Q:0.720 Epsilon:0.12 Duration:44.32 Step:2584 CStep:208586\n",
            "Episode:162 Time:09:59:12 Reward:-16.00 Loss:3.88 Last_100_Avg_Rew:-17.420 Avg_Max_Q:0.761 Epsilon:0.12 Duration:31.77 Step:1881 CStep:210468\n",
            "Episode:163 Time:09:59:38 Reward:-18.00 Loss:3.36 Last_100_Avg_Rew:-17.410 Avg_Max_Q:0.762 Epsilon:0.12 Duration:26.23 Step:1523 CStep:211992\n",
            "Episode:164 Time:10:00:16 Reward:-15.00 Loss:4.53 Last_100_Avg_Rew:-17.370 Avg_Max_Q:0.811 Epsilon:0.12 Duration:37.48 Step:2184 CStep:214177\n",
            "Episode:165 Time:10:00:59 Reward:-10.00 Loss:4.99 Last_100_Avg_Rew:-17.270 Avg_Max_Q:0.863 Epsilon:0.11 Duration:43.61 Step:2490 CStep:216668\n",
            "Episode:166 Time:10:01:27 Reward:-17.00 Loss:3.29 Last_100_Avg_Rew:-17.230 Avg_Max_Q:0.884 Epsilon:0.11 Duration:27.67 Step:1609 CStep:218278\n",
            "Episode:167 Time:10:01:59 Reward:-17.00 Loss:3.53 Last_100_Avg_Rew:-17.190 Avg_Max_Q:0.906 Epsilon:0.11 Duration:31.93 Step:1865 CStep:220144\n",
            "Episode:168 Time:10:02:21 Reward:-20.00 Loss:3.04 Last_100_Avg_Rew:-17.190 Avg_Max_Q:0.912 Epsilon:0.11 Duration:22.15 Step:1308 CStep:221453\n",
            "Episode:169 Time:10:02:57 Reward:-16.00 Loss:4.48 Last_100_Avg_Rew:-17.160 Avg_Max_Q:0.901 Epsilon:0.11 Duration:35.41 Step:2063 CStep:223517\n",
            "Episode:170 Time:10:03:27 Reward:-17.00 Loss:4.51 Last_100_Avg_Rew:-17.140 Avg_Max_Q:0.936 Epsilon:0.10 Duration:30.40 Step:1790 CStep:225308\n",
            "Episode:171 Time:10:04:01 Reward:-16.00 Loss:4.37 Last_100_Avg_Rew:-17.110 Avg_Max_Q:0.948 Epsilon:0.10 Duration:34.26 Step:1998 CStep:227307\n",
            "Episode:172 Time:10:04:37 Reward:-13.00 Loss:4.96 Last_100_Avg_Rew:-17.040 Avg_Max_Q:0.966 Epsilon:0.10 Duration:36.18 Step:2050 CStep:229358\n",
            "Episode:173 Time:10:05:08 Reward:-17.00 Loss:3.96 Last_100_Avg_Rew:-17.000 Avg_Max_Q:0.959 Epsilon:0.10 Duration:30.64 Step:1789 CStep:231148\n",
            "Episode:174 Time:10:05:45 Reward:-13.00 Loss:4.44 Last_100_Avg_Rew:-16.930 Avg_Max_Q:0.942 Epsilon:0.10 Duration:36.97 Step:2152 CStep:233301\n",
            "Episode:175 Time:10:06:19 Reward:-14.00 Loss:4.34 Last_100_Avg_Rew:-16.860 Avg_Max_Q:0.929 Epsilon:0.09 Duration:33.54 Step:1944 CStep:235246\n",
            "Episode:176 Time:10:07:01 Reward:-10.00 Loss:5.05 Last_100_Avg_Rew:-16.760 Avg_Max_Q:0.890 Epsilon:0.09 Duration:42.81 Step:2491 CStep:237738\n",
            "Episode:177 Time:10:07:40 Reward:-12.00 Loss:4.94 Last_100_Avg_Rew:-16.670 Avg_Max_Q:0.917 Epsilon:0.09 Duration:38.83 Step:2265 CStep:240004\n",
            "Episode:178 Time:10:08:10 Reward:-16.00 Loss:4.26 Last_100_Avg_Rew:-16.630 Avg_Max_Q:0.911 Epsilon:0.09 Duration:29.53 Step:1726 CStep:241731\n",
            "Episode:179 Time:10:08:51 Reward:-15.00 Loss:4.51 Last_100_Avg_Rew:-16.600 Avg_Max_Q:0.814 Epsilon:0.09 Duration:41.24 Step:2346 CStep:244078\n",
            "Episode:180 Time:10:09:36 Reward:-8.00 Loss:5.10 Last_100_Avg_Rew:-16.470 Avg_Max_Q:0.850 Epsilon:0.08 Duration:44.66 Step:2613 CStep:246692\n",
            "Episode:181 Time:10:10:12 Reward:-12.00 Loss:4.31 Last_100_Avg_Rew:-16.400 Avg_Max_Q:0.883 Epsilon:0.08 Duration:36.06 Step:2107 CStep:248800\n",
            "Episode:182 Time:10:10:46 Reward:-14.00 Loss:4.36 Last_100_Avg_Rew:-16.360 Avg_Max_Q:0.893 Epsilon:0.08 Duration:33.88 Step:1953 CStep:250754\n",
            "Episode:183 Time:10:11:27 Reward:-9.00 Loss:4.92 Last_100_Avg_Rew:-16.250 Avg_Max_Q:0.920 Epsilon:0.08 Duration:40.96 Step:2361 CStep:253116\n",
            "Episode:184 Time:10:12:07 Reward:-12.00 Loss:5.11 Last_100_Avg_Rew:-16.190 Avg_Max_Q:0.917 Epsilon:0.08 Duration:40.09 Step:2315 CStep:255432\n",
            "Episode:185 Time:10:12:48 Reward:-12.00 Loss:5.00 Last_100_Avg_Rew:-16.130 Avg_Max_Q:0.922 Epsilon:0.08 Duration:41.48 Step:2345 CStep:257778\n",
            "Episode:186 Time:10:13:19 Reward:-16.00 Loss:4.21 Last_100_Avg_Rew:-16.100 Avg_Max_Q:0.920 Epsilon:0.07 Duration:30.66 Step:1758 CStep:259537\n",
            "Episode:187 Time:10:14:08 Reward:-7.00 Loss:5.65 Last_100_Avg_Rew:-15.970 Avg_Max_Q:0.866 Epsilon:0.07 Duration:49.44 Step:2840 CStep:262378\n",
            "Episode:188 Time:10:14:57 Reward:-8.00 Loss:5.45 Last_100_Avg_Rew:-15.860 Avg_Max_Q:0.823 Epsilon:0.07 Duration:49.14 Step:2817 CStep:265196\n",
            "Episode:189 Time:10:15:39 Reward:-11.00 Loss:4.90 Last_100_Avg_Rew:-15.780 Avg_Max_Q:0.844 Epsilon:0.07 Duration:41.35 Step:2347 CStep:267544\n",
            "Episode:190 Time:10:16:15 Reward:-17.00 Loss:4.56 Last_100_Avg_Rew:-15.770 Avg_Max_Q:0.884 Epsilon:0.07 Duration:35.77 Step:2049 CStep:269594\n",
            "Episode:191 Time:10:16:51 Reward:-14.00 Loss:4.88 Last_100_Avg_Rew:-15.740 Avg_Max_Q:0.940 Epsilon:0.07 Duration:36.53 Step:2115 CStep:271710\n",
            "Episode:192 Time:10:17:31 Reward:-10.00 Loss:5.33 Last_100_Avg_Rew:-15.650 Avg_Max_Q:0.974 Epsilon:0.06 Duration:39.72 Step:2300 CStep:274011\n",
            "Episode:193 Time:10:18:11 Reward:-11.00 Loss:4.75 Last_100_Avg_Rew:-15.570 Avg_Max_Q:0.950 Epsilon:0.06 Duration:40.57 Step:2346 CStep:276358\n",
            "Episode:194 Time:10:18:54 Reward:-11.00 Loss:5.38 Last_100_Avg_Rew:-15.500 Avg_Max_Q:0.966 Epsilon:0.06 Duration:42.52 Step:2482 CStep:278841\n",
            "Episode:195 Time:10:19:46 Reward:-5.00 Loss:6.97 Last_100_Avg_Rew:-15.390 Avg_Max_Q:0.968 Epsilon:0.06 Duration:51.97 Step:2999 CStep:281841\n",
            "Episode:196 Time:10:20:32 Reward:-10.00 Loss:6.93 Last_100_Avg_Rew:-15.320 Avg_Max_Q:0.983 Epsilon:0.06 Duration:45.60 Step:2627 CStep:284469\n",
            "Episode:197 Time:10:21:11 Reward:-13.00 Loss:6.60 Last_100_Avg_Rew:-15.260 Avg_Max_Q:1.010 Epsilon:0.06 Duration:39.75 Step:2298 CStep:286768\n",
            "Episode:198 Time:10:21:56 Reward:-10.00 Loss:6.33 Last_100_Avg_Rew:-15.240 Avg_Max_Q:0.991 Epsilon:0.05 Duration:45.13 Step:2585 CStep:289354\n",
            "Episode:199 Time:10:22:36 Reward:-14.00 Loss:5.78 Last_100_Avg_Rew:-15.210 Avg_Max_Q:0.994 Epsilon:0.05 Duration:39.95 Step:2322 CStep:291677\n",
            "Episode:200 Time:10:23:08 Reward:-14.00 Loss:4.88 Last_100_Avg_Rew:-15.180 Avg_Max_Q:1.014 Epsilon:0.05 Duration:31.67 Step:1829 CStep:293507\n",
            "Episode:201 Time:10:23:46 Reward:-13.00 Loss:4.92 Last_100_Avg_Rew:-15.140 Avg_Max_Q:0.986 Epsilon:0.05 Duration:38.04 Step:2179 CStep:295687\n",
            "Episode:202 Time:10:24:26 Reward:-13.00 Loss:5.30 Last_100_Avg_Rew:-15.070 Avg_Max_Q:0.996 Epsilon:0.05 Duration:40.11 Step:2336 CStep:298024\n",
            "Episode:203 Time:10:25:05 Reward:-11.00 Loss:5.47 Last_100_Avg_Rew:-14.970 Avg_Max_Q:0.997 Epsilon:0.05 Duration:38.57 Step:2252 CStep:300277\n",
            "Episode:204 Time:10:25:47 Reward:-8.00 Loss:6.04 Last_100_Avg_Rew:-14.860 Avg_Max_Q:1.044 Epsilon:0.05 Duration:42.28 Step:2481 CStep:302759\n",
            "Episode:205 Time:10:26:23 Reward:-14.00 Loss:6.13 Last_100_Avg_Rew:-14.830 Avg_Max_Q:1.049 Epsilon:0.05 Duration:35.99 Step:2099 CStep:304859\n",
            "Episode:206 Time:10:27:20 Reward:-3.00 Loss:8.17 Last_100_Avg_Rew:-14.660 Avg_Max_Q:1.042 Epsilon:0.05 Duration:56.99 Step:3260 CStep:308120\n",
            "Episode:207 Time:10:27:59 Reward:-11.00 Loss:6.57 Last_100_Avg_Rew:-14.610 Avg_Max_Q:1.039 Epsilon:0.05 Duration:38.98 Step:2269 CStep:310390\n",
            "Episode:208 Time:10:28:46 Reward:-9.00 Loss:7.90 Last_100_Avg_Rew:-14.510 Avg_Max_Q:1.065 Epsilon:0.05 Duration:46.58 Step:2741 CStep:313132\n",
            "Episode:209 Time:10:29:31 Reward:-10.00 Loss:6.94 Last_100_Avg_Rew:-14.420 Avg_Max_Q:1.065 Epsilon:0.05 Duration:45.89 Step:2663 CStep:315796\n",
            "Episode:210 Time:10:30:21 Reward:-4.00 Loss:7.56 Last_100_Avg_Rew:-14.300 Avg_Max_Q:1.079 Epsilon:0.05 Duration:49.18 Step:2868 CStep:318665\n",
            "Episode:211 Time:10:31:09 Reward:-10.00 Loss:6.71 Last_100_Avg_Rew:-14.200 Avg_Max_Q:1.004 Epsilon:0.05 Duration:48.34 Step:2760 CStep:321426\n",
            "Episode:212 Time:10:31:54 Reward:-10.00 Loss:7.09 Last_100_Avg_Rew:-14.140 Avg_Max_Q:1.047 Epsilon:0.05 Duration:45.49 Step:2659 CStep:324086\n",
            "Episode:213 Time:10:32:45 Reward:-10.00 Loss:8.16 Last_100_Avg_Rew:-14.040 Avg_Max_Q:1.043 Epsilon:0.05 Duration:50.81 Step:2969 CStep:327056\n",
            "Episode:214 Time:10:33:20 Reward:-14.00 Loss:6.40 Last_100_Avg_Rew:-14.030 Avg_Max_Q:1.079 Epsilon:0.05 Duration:35.19 Step:2040 CStep:329097\n",
            "Episode:215 Time:10:34:03 Reward:-11.00 Loss:7.05 Last_100_Avg_Rew:-13.950 Avg_Max_Q:1.076 Epsilon:0.05 Duration:42.70 Step:2494 CStep:331592\n",
            "Episode:216 Time:10:34:53 Reward:-6.00 Loss:8.19 Last_100_Avg_Rew:-13.830 Avg_Max_Q:1.093 Epsilon:0.05 Duration:49.78 Step:2842 CStep:334435\n",
            "Episode:217 Time:10:35:30 Reward:-13.00 Loss:6.81 Last_100_Avg_Rew:-13.760 Avg_Max_Q:1.093 Epsilon:0.05 Duration:36.95 Step:2135 CStep:336571\n",
            "Episode:218 Time:10:36:08 Reward:-13.00 Loss:7.02 Last_100_Avg_Rew:-13.690 Avg_Max_Q:1.095 Epsilon:0.05 Duration:38.34 Step:2200 CStep:338772\n",
            "Episode:219 Time:10:36:52 Reward:-11.00 Loss:7.12 Last_100_Avg_Rew:-13.640 Avg_Max_Q:1.056 Epsilon:0.05 Duration:44.10 Step:2499 CStep:341272\n",
            "Episode:220 Time:10:37:37 Reward:-10.00 Loss:6.83 Last_100_Avg_Rew:-13.540 Avg_Max_Q:1.049 Epsilon:0.05 Duration:44.98 Step:2586 CStep:343859\n",
            "Episode:221 Time:10:38:22 Reward:-10.00 Loss:7.71 Last_100_Avg_Rew:-13.550 Avg_Max_Q:1.051 Epsilon:0.05 Duration:44.18 Step:2524 CStep:346384\n",
            "Episode:222 Time:10:39:12 Reward:-4.00 Loss:8.45 Last_100_Avg_Rew:-13.420 Avg_Max_Q:1.022 Epsilon:0.05 Duration:50.63 Step:2896 CStep:349281\n",
            "Episode:223 Time:10:40:02 Reward:-7.00 Loss:8.19 Last_100_Avg_Rew:-13.340 Avg_Max_Q:1.044 Epsilon:0.05 Duration:50.14 Step:2917 CStep:352199\n",
            "Episode:224 Time:10:40:41 Reward:-12.00 Loss:6.64 Last_100_Avg_Rew:-13.290 Avg_Max_Q:1.044 Epsilon:0.05 Duration:38.97 Step:2239 CStep:354439\n",
            "Episode:225 Time:10:41:43 Reward:-2.00 Loss:8.40 Last_100_Avg_Rew:-13.110 Avg_Max_Q:1.027 Epsilon:0.05 Duration:61.54 Step:3576 CStep:358016\n",
            "Episode:226 Time:10:42:30 Reward:-7.00 Loss:7.60 Last_100_Avg_Rew:-13.040 Avg_Max_Q:1.062 Epsilon:0.05 Duration:46.83 Step:2677 CStep:360694\n",
            "Episode:227 Time:10:43:12 Reward:-9.00 Loss:7.54 Last_100_Avg_Rew:-12.940 Avg_Max_Q:1.080 Epsilon:0.05 Duration:42.67 Step:2449 CStep:363144\n",
            "Episode:228 Time:10:44:05 Reward:-8.00 Loss:9.36 Last_100_Avg_Rew:-12.860 Avg_Max_Q:1.101 Epsilon:0.05 Duration:52.85 Step:3055 CStep:366200\n",
            "Episode:229 Time:10:44:48 Reward:-7.00 Loss:8.18 Last_100_Avg_Rew:-12.750 Avg_Max_Q:1.106 Epsilon:0.05 Duration:43.24 Step:2519 CStep:368720\n",
            "Episode:230 Time:10:45:38 Reward:-5.00 Loss:8.31 Last_100_Avg_Rew:-12.640 Avg_Max_Q:1.091 Epsilon:0.05 Duration:49.73 Step:2882 CStep:371603\n",
            "Episode:231 Time:10:46:25 Reward:9.00 Loss:7.26 Last_100_Avg_Rew:-12.360 Avg_Max_Q:1.106 Epsilon:0.05 Duration:47.29 Step:2687 CStep:374291\n",
            "Episode:232 Time:10:46:52 Reward:-18.00 Loss:4.57 Last_100_Avg_Rew:-12.380 Avg_Max_Q:1.069 Epsilon:0.05 Duration:26.07 Step:1495 CStep:375787\n",
            "Episode:233 Time:10:47:41 Reward:-4.00 Loss:6.97 Last_100_Avg_Rew:-12.290 Avg_Max_Q:1.090 Epsilon:0.05 Duration:49.54 Step:2874 CStep:378662\n",
            "Episode:234 Time:10:48:25 Reward:7.00 Loss:6.27 Last_100_Avg_Rew:-12.120 Avg_Max_Q:1.106 Epsilon:0.05 Duration:44.16 Step:2574 CStep:381237\n",
            "Episode:235 Time:10:49:12 Reward:9.00 Loss:6.21 Last_100_Avg_Rew:-11.830 Avg_Max_Q:1.104 Epsilon:0.05 Duration:46.56 Step:2718 CStep:383956\n",
            "Episode:236 Time:10:50:06 Reward:5.00 Loss:6.54 Last_100_Avg_Rew:-11.620 Avg_Max_Q:1.078 Epsilon:0.05 Duration:53.96 Step:3133 CStep:387090\n",
            "Episode:237 Time:10:50:50 Reward:6.00 Loss:6.08 Last_100_Avg_Rew:-11.400 Avg_Max_Q:1.094 Epsilon:0.05 Duration:44.58 Step:2619 CStep:389710\n",
            "Episode:238 Time:10:51:42 Reward:1.00 Loss:6.60 Last_100_Avg_Rew:-11.190 Avg_Max_Q:1.090 Epsilon:0.05 Duration:51.47 Step:3012 CStep:392723\n",
            "Episode:239 Time:10:52:37 Reward:-6.00 Loss:6.93 Last_100_Avg_Rew:-11.050 Avg_Max_Q:1.066 Epsilon:0.05 Duration:55.45 Step:3242 CStep:395966\n",
            "Episode:240 Time:10:53:32 Reward:3.00 Loss:7.06 Last_100_Avg_Rew:-10.850 Avg_Max_Q:1.081 Epsilon:0.05 Duration:55.12 Step:3199 CStep:399166\n",
            "Episode:241 Time:10:54:24 Reward:5.00 Loss:7.60 Last_100_Avg_Rew:-10.640 Avg_Max_Q:1.102 Epsilon:0.05 Duration:51.69 Step:3034 CStep:402201\n",
            "Episode:242 Time:10:55:13 Reward:4.00 Loss:6.30 Last_100_Avg_Rew:-10.430 Avg_Max_Q:1.099 Epsilon:0.05 Duration:48.74 Step:2860 CStep:405062\n",
            "Episode:243 Time:10:55:57 Reward:10.00 Loss:5.37 Last_100_Avg_Rew:-10.160 Avg_Max_Q:1.075 Epsilon:0.05 Duration:44.01 Step:2598 CStep:407661\n",
            "Episode:244 Time:10:56:43 Reward:8.00 Loss:5.30 Last_100_Avg_Rew:-9.880 Avg_Max_Q:1.085 Epsilon:0.05 Duration:46.61 Step:2737 CStep:410399\n",
            "Episode:245 Time:10:57:21 Reward:15.00 Loss:4.10 Last_100_Avg_Rew:-9.530 Avg_Max_Q:1.091 Epsilon:0.05 Duration:37.28 Step:2138 CStep:412538\n",
            "Episode:246 Time:10:58:11 Reward:5.00 Loss:4.91 Last_100_Avg_Rew:-9.320 Avg_Max_Q:1.078 Epsilon:0.05 Duration:50.09 Step:2937 CStep:415476\n",
            "Episode:247 Time:10:58:57 Reward:8.00 Loss:4.74 Last_100_Avg_Rew:-9.080 Avg_Max_Q:1.060 Epsilon:0.05 Duration:45.97 Step:2685 CStep:418162\n",
            "Episode:248 Time:10:59:46 Reward:4.00 Loss:5.07 Last_100_Avg_Rew:-8.920 Avg_Max_Q:1.048 Epsilon:0.05 Duration:49.21 Step:2904 CStep:421067\n",
            "Episode:249 Time:11:00:38 Reward:-2.00 Loss:5.04 Last_100_Avg_Rew:-8.770 Avg_Max_Q:1.070 Epsilon:0.05 Duration:52.36 Step:3052 CStep:424120\n",
            "Episode:250 Time:11:01:22 Reward:10.00 Loss:4.22 Last_100_Avg_Rew:-8.540 Avg_Max_Q:1.102 Epsilon:0.05 Duration:43.15 Step:2471 CStep:426592\n",
            "Episode:251 Time:11:02:13 Reward:3.00 Loss:4.72 Last_100_Avg_Rew:-8.350 Avg_Max_Q:1.078 Epsilon:0.05 Duration:51.76 Step:3070 CStep:429663\n",
            "Episode:252 Time:11:03:09 Reward:4.00 Loss:5.10 Last_100_Avg_Rew:-8.190 Avg_Max_Q:1.072 Epsilon:0.05 Duration:55.79 Step:3167 CStep:432831\n",
            "Episode:253 Time:11:03:59 Reward:3.00 Loss:4.87 Last_100_Avg_Rew:-8.060 Avg_Max_Q:1.077 Epsilon:0.05 Duration:49.88 Step:2907 CStep:435739\n",
            "Episode:254 Time:11:04:44 Reward:8.00 Loss:4.11 Last_100_Avg_Rew:-7.810 Avg_Max_Q:1.070 Epsilon:0.05 Duration:44.54 Step:2502 CStep:438242\n",
            "Episode:255 Time:11:05:35 Reward:-2.00 Loss:4.32 Last_100_Avg_Rew:-7.680 Avg_Max_Q:1.063 Epsilon:0.05 Duration:51.87 Step:2984 CStep:441227\n",
            "Episode:256 Time:11:06:24 Reward:5.00 Loss:4.52 Last_100_Avg_Rew:-7.500 Avg_Max_Q:1.092 Epsilon:0.05 Duration:48.90 Step:2782 CStep:444010\n",
            "Episode:257 Time:11:07:07 Reward:11.00 Loss:3.89 Last_100_Avg_Rew:-7.230 Avg_Max_Q:1.103 Epsilon:0.05 Duration:43.18 Step:2469 CStep:446480\n",
            "Episode:258 Time:11:07:54 Reward:10.00 Loss:4.18 Last_100_Avg_Rew:-7.020 Avg_Max_Q:1.091 Epsilon:0.05 Duration:46.66 Step:2546 CStep:449027\n",
            "Episode:259 Time:11:08:41 Reward:9.00 Loss:4.23 Last_100_Avg_Rew:-6.790 Avg_Max_Q:1.060 Epsilon:0.05 Duration:46.49 Step:2563 CStep:451591\n",
            "Episode:260 Time:11:09:27 Reward:6.00 Loss:4.03 Last_100_Avg_Rew:-6.600 Avg_Max_Q:1.077 Epsilon:0.05 Duration:46.84 Step:2626 CStep:454218\n",
            "Episode:261 Time:11:10:22 Reward:-1.00 Loss:4.62 Last_100_Avg_Rew:-6.500 Avg_Max_Q:1.073 Epsilon:0.05 Duration:54.53 Step:3196 CStep:457415\n",
            "Episode:262 Time:11:11:14 Reward:1.00 Loss:5.10 Last_100_Avg_Rew:-6.330 Avg_Max_Q:1.115 Epsilon:0.05 Duration:52.34 Step:3011 CStep:460427\n",
            "Episode:263 Time:11:11:58 Reward:8.00 Loss:4.39 Last_100_Avg_Rew:-6.070 Avg_Max_Q:1.113 Epsilon:0.05 Duration:43.46 Step:2496 CStep:462924\n",
            "Episode:264 Time:11:12:48 Reward:8.00 Loss:4.85 Last_100_Avg_Rew:-5.840 Avg_Max_Q:1.110 Epsilon:0.05 Duration:50.60 Step:2976 CStep:465901\n",
            "Episode:265 Time:11:13:25 Reward:15.00 Loss:3.62 Last_100_Avg_Rew:-5.590 Avg_Max_Q:1.108 Epsilon:0.05 Duration:36.51 Step:2152 CStep:468054\n",
            "Episode:266 Time:11:14:04 Reward:12.00 Loss:3.89 Last_100_Avg_Rew:-5.300 Avg_Max_Q:1.099 Epsilon:0.05 Duration:39.44 Step:2305 CStep:470360\n",
            "Episode:267 Time:11:14:49 Reward:7.00 Loss:4.25 Last_100_Avg_Rew:-5.060 Avg_Max_Q:1.078 Epsilon:0.05 Duration:44.42 Step:2612 CStep:472973\n",
            "Episode:268 Time:11:15:40 Reward:-4.00 Loss:4.19 Last_100_Avg_Rew:-4.900 Avg_Max_Q:1.076 Epsilon:0.05 Duration:51.70 Step:2926 CStep:475900\n",
            "Episode:269 Time:11:16:22 Reward:10.00 Loss:3.99 Last_100_Avg_Rew:-4.640 Avg_Max_Q:1.096 Epsilon:0.05 Duration:41.17 Step:2415 CStep:478316\n",
            "Episode:270 Time:11:16:59 Reward:13.00 Loss:3.37 Last_100_Avg_Rew:-4.340 Avg_Max_Q:1.084 Epsilon:0.05 Duration:37.75 Step:2201 CStep:480518\n",
            "Episode:271 Time:11:17:58 Reward:3.00 Loss:4.56 Last_100_Avg_Rew:-4.150 Avg_Max_Q:1.087 Epsilon:0.05 Duration:58.37 Step:3422 CStep:483941\n",
            "Episode:272 Time:11:18:43 Reward:8.00 Loss:3.77 Last_100_Avg_Rew:-3.940 Avg_Max_Q:1.091 Epsilon:0.05 Duration:45.29 Step:2654 CStep:486596\n",
            "Episode:273 Time:11:19:22 Reward:12.00 Loss:3.21 Last_100_Avg_Rew:-3.650 Avg_Max_Q:1.092 Epsilon:0.05 Duration:38.83 Step:2213 CStep:488810\n",
            "Episode:274 Time:11:20:03 Reward:7.00 Loss:3.14 Last_100_Avg_Rew:-3.450 Avg_Max_Q:1.090 Epsilon:0.05 Duration:41.27 Step:2431 CStep:491242\n",
            "Episode:275 Time:11:20:48 Reward:8.00 Loss:3.38 Last_100_Avg_Rew:-3.230 Avg_Max_Q:1.087 Epsilon:0.05 Duration:44.82 Step:2655 CStep:493898\n",
            "Episode:276 Time:11:21:36 Reward:6.00 Loss:3.63 Last_100_Avg_Rew:-3.070 Avg_Max_Q:1.080 Epsilon:0.05 Duration:48.39 Step:2731 CStep:496630\n",
            "Episode:277 Time:11:22:14 Reward:11.00 Loss:3.18 Last_100_Avg_Rew:-2.840 Avg_Max_Q:1.081 Epsilon:0.05 Duration:37.82 Step:2208 CStep:498839\n",
            "Episode:278 Time:11:22:59 Reward:9.00 Loss:3.56 Last_100_Avg_Rew:-2.590 Avg_Max_Q:1.093 Epsilon:0.05 Duration:44.43 Step:2563 CStep:501403\n",
            "Episode:279 Time:11:23:45 Reward:3.00 Loss:3.74 Last_100_Avg_Rew:-2.410 Avg_Max_Q:1.093 Epsilon:0.05 Duration:46.68 Step:2771 CStep:504175\n",
            "Episode:280 Time:11:24:34 Reward:6.00 Loss:3.93 Last_100_Avg_Rew:-2.270 Avg_Max_Q:1.102 Epsilon:0.05 Duration:48.58 Step:2867 CStep:507043\n",
            "Episode:281 Time:11:25:12 Reward:14.00 Loss:3.36 Last_100_Avg_Rew:-2.010 Avg_Max_Q:1.109 Epsilon:0.05 Duration:38.52 Step:2222 CStep:509266\n",
            "Episode:282 Time:11:25:52 Reward:-12.00 Loss:3.60 Last_100_Avg_Rew:-1.990 Avg_Max_Q:1.113 Epsilon:0.05 Duration:39.35 Step:2282 CStep:511549\n",
            "Episode:283 Time:11:26:23 Reward:19.00 Loss:3.08 Last_100_Avg_Rew:-1.710 Avg_Max_Q:1.124 Epsilon:0.05 Duration:31.16 Step:1764 CStep:513314\n",
            "Episode:284 Time:11:27:10 Reward:-2.00 Loss:4.04 Last_100_Avg_Rew:-1.610 Avg_Max_Q:1.114 Epsilon:0.05 Duration:47.02 Step:2804 CStep:516119\n",
            "Episode:285 Time:11:27:49 Reward:12.00 Loss:3.45 Last_100_Avg_Rew:-1.370 Avg_Max_Q:1.105 Epsilon:0.05 Duration:38.84 Step:2285 CStep:518405\n",
            "Episode:286 Time:11:28:20 Reward:18.00 Loss:2.95 Last_100_Avg_Rew:-1.030 Avg_Max_Q:1.092 Epsilon:0.05 Duration:31.19 Step:1832 CStep:520238\n",
            "Episode:287 Time:11:29:08 Reward:9.00 Loss:3.74 Last_100_Avg_Rew:-0.870 Avg_Max_Q:1.099 Epsilon:0.05 Duration:47.63 Step:2780 CStep:523019\n",
            "Episode:288 Time:11:29:37 Reward:20.00 Loss:2.53 Last_100_Avg_Rew:-0.590 Avg_Max_Q:1.101 Epsilon:0.05 Duration:29.64 Step:1722 CStep:524742\n",
            "Episode:289 Time:11:30:20 Reward:9.00 Loss:3.52 Last_100_Avg_Rew:-0.390 Avg_Max_Q:1.103 Epsilon:0.05 Duration:43.17 Step:2523 CStep:527266\n",
            "Episode:290 Time:11:31:02 Reward:9.00 Loss:3.58 Last_100_Avg_Rew:-0.130 Avg_Max_Q:1.123 Epsilon:0.05 Duration:41.88 Step:2463 CStep:529730\n",
            "Episode:291 Time:11:31:47 Reward:7.00 Loss:4.24 Last_100_Avg_Rew:0.080 Avg_Max_Q:1.120 Epsilon:0.05 Duration:44.66 Step:2669 CStep:532400\n",
            "Episode:292 Time:11:32:35 Reward:4.00 Loss:4.50 Last_100_Avg_Rew:0.220 Avg_Max_Q:1.109 Epsilon:0.05 Duration:47.65 Step:2832 CStep:535233\n",
            "Episode:293 Time:11:33:12 Reward:10.00 Loss:3.48 Last_100_Avg_Rew:0.430 Avg_Max_Q:1.113 Epsilon:0.05 Duration:37.48 Step:2205 CStep:537439\n",
            "Episode:294 Time:11:33:47 Reward:17.00 Loss:2.96 Last_100_Avg_Rew:0.710 Avg_Max_Q:1.112 Epsilon:0.05 Duration:35.14 Step:2021 CStep:539461\n",
            "Episode:295 Time:11:34:22 Reward:15.00 Loss:2.59 Last_100_Avg_Rew:0.910 Avg_Max_Q:1.115 Epsilon:0.05 Duration:34.39 Step:1942 CStep:541404\n",
            "Episode:296 Time:11:34:53 Reward:20.00 Loss:2.34 Last_100_Avg_Rew:1.210 Avg_Max_Q:1.116 Epsilon:0.05 Duration:31.33 Step:1793 CStep:543198\n",
            "Episode:297 Time:11:35:28 Reward:14.00 Loss:2.68 Last_100_Avg_Rew:1.480 Avg_Max_Q:1.139 Epsilon:0.05 Duration:34.97 Step:2094 CStep:545293\n",
            "Episode:298 Time:11:36:08 Reward:11.00 Loss:3.04 Last_100_Avg_Rew:1.690 Avg_Max_Q:1.134 Epsilon:0.05 Duration:39.89 Step:2362 CStep:547656\n",
            "Episode:299 Time:11:36:43 Reward:16.00 Loss:2.81 Last_100_Avg_Rew:1.990 Avg_Max_Q:1.126 Epsilon:0.05 Duration:34.67 Step:2082 CStep:549739\n",
            "Episode:300 Time:11:37:16 Reward:17.00 Loss:2.32 Last_100_Avg_Rew:2.300 Avg_Max_Q:1.123 Epsilon:0.05 Duration:33.11 Step:1923 CStep:551663\n",
            "Episode:301 Time:11:37:49 Reward:17.00 Loss:2.32 Last_100_Avg_Rew:2.600 Avg_Max_Q:1.120 Epsilon:0.05 Duration:33.09 Step:1979 CStep:553643\n",
            "Episode:302 Time:11:38:35 Reward:5.00 Loss:3.21 Last_100_Avg_Rew:2.780 Avg_Max_Q:1.123 Epsilon:0.05 Duration:46.44 Step:2775 CStep:556419\n",
            "Episode:303 Time:11:39:10 Reward:15.00 Loss:2.62 Last_100_Avg_Rew:3.040 Avg_Max_Q:1.129 Epsilon:0.05 Duration:34.86 Step:2070 CStep:558490\n",
            "Episode:304 Time:11:39:49 Reward:10.00 Loss:2.81 Last_100_Avg_Rew:3.220 Avg_Max_Q:1.133 Epsilon:0.05 Duration:38.57 Step:2323 CStep:560814\n",
            "Episode:305 Time:11:40:24 Reward:15.00 Loss:2.54 Last_100_Avg_Rew:3.510 Avg_Max_Q:1.145 Epsilon:0.05 Duration:35.62 Step:2092 CStep:562907\n",
            "Episode:306 Time:11:40:54 Reward:19.00 Loss:2.13 Last_100_Avg_Rew:3.730 Avg_Max_Q:1.134 Epsilon:0.05 Duration:29.91 Step:1817 CStep:564725\n",
            "Episode:307 Time:11:41:35 Reward:10.00 Loss:2.97 Last_100_Avg_Rew:3.940 Avg_Max_Q:1.146 Epsilon:0.05 Duration:40.62 Step:2472 CStep:567198\n",
            "Episode:308 Time:11:42:21 Reward:-5.00 Loss:3.51 Last_100_Avg_Rew:3.980 Avg_Max_Q:1.142 Epsilon:0.05 Duration:46.01 Step:2755 CStep:569954\n",
            "Episode:309 Time:11:42:57 Reward:14.00 Loss:2.96 Last_100_Avg_Rew:4.220 Avg_Max_Q:1.146 Epsilon:0.05 Duration:36.19 Step:2192 CStep:572147\n",
            "Episode:310 Time:11:43:28 Reward:18.00 Loss:2.57 Last_100_Avg_Rew:4.440 Avg_Max_Q:1.133 Epsilon:0.05 Duration:31.01 Step:1888 CStep:574036\n",
            "Episode:311 Time:11:44:13 Reward:8.00 Loss:3.39 Last_100_Avg_Rew:4.620 Avg_Max_Q:1.140 Epsilon:0.05 Duration:45.00 Step:2678 CStep:576715\n",
            "Episode:312 Time:11:44:47 Reward:14.00 Loss:2.71 Last_100_Avg_Rew:4.860 Avg_Max_Q:1.115 Epsilon:0.05 Duration:33.73 Step:2041 CStep:578757\n",
            "Episode:313 Time:11:45:18 Reward:17.00 Loss:2.21 Last_100_Avg_Rew:5.130 Avg_Max_Q:1.113 Epsilon:0.05 Duration:30.82 Step:1849 CStep:580607\n",
            "Episode:314 Time:11:45:53 Reward:14.00 Loss:2.23 Last_100_Avg_Rew:5.410 Avg_Max_Q:1.117 Epsilon:0.05 Duration:35.53 Step:2132 CStep:582740\n",
            "Episode:315 Time:11:46:25 Reward:16.00 Loss:2.17 Last_100_Avg_Rew:5.680 Avg_Max_Q:1.141 Epsilon:0.05 Duration:32.36 Step:1959 CStep:584700\n",
            "Episode:316 Time:11:47:04 Reward:12.00 Loss:2.23 Last_100_Avg_Rew:5.860 Avg_Max_Q:1.140 Epsilon:0.05 Duration:38.29 Step:2297 CStep:586998\n",
            "Episode:317 Time:11:47:48 Reward:6.00 Loss:2.52 Last_100_Avg_Rew:6.050 Avg_Max_Q:1.133 Epsilon:0.05 Duration:44.40 Step:2603 CStep:589602\n",
            "Episode:318 Time:11:48:20 Reward:17.00 Loss:2.18 Last_100_Avg_Rew:6.350 Avg_Max_Q:1.133 Epsilon:0.05 Duration:31.46 Step:1914 CStep:591517\n",
            "Episode:319 Time:11:49:04 Reward:5.00 Loss:2.69 Last_100_Avg_Rew:6.510 Avg_Max_Q:1.144 Epsilon:0.05 Duration:44.18 Step:2645 CStep:594163\n",
            "Episode:320 Time:11:49:43 Reward:10.00 Loss:2.71 Last_100_Avg_Rew:6.710 Avg_Max_Q:1.145 Epsilon:0.05 Duration:39.48 Step:2398 CStep:596562\n",
            "Episode:321 Time:11:50:25 Reward:10.00 Loss:3.03 Last_100_Avg_Rew:6.910 Avg_Max_Q:1.138 Epsilon:0.05 Duration:41.90 Step:2541 CStep:599104\n",
            "Episode:322 Time:11:51:01 Reward:13.00 Loss:2.63 Last_100_Avg_Rew:7.080 Avg_Max_Q:1.146 Epsilon:0.05 Duration:36.20 Step:2129 CStep:601234\n",
            "Episode:323 Time:11:51:47 Reward:8.00 Loss:3.36 Last_100_Avg_Rew:7.230 Avg_Max_Q:1.128 Epsilon:0.05 Duration:45.75 Step:2745 CStep:603980\n",
            "Episode:324 Time:11:52:22 Reward:13.00 Loss:2.75 Last_100_Avg_Rew:7.480 Avg_Max_Q:1.130 Epsilon:0.05 Duration:34.78 Step:2116 CStep:606097\n",
            "Episode:325 Time:11:52:58 Reward:12.00 Loss:2.55 Last_100_Avg_Rew:7.620 Avg_Max_Q:1.114 Epsilon:0.05 Duration:36.12 Step:2178 CStep:608276\n",
            "Episode:326 Time:11:53:36 Reward:12.00 Loss:2.81 Last_100_Avg_Rew:7.810 Avg_Max_Q:1.125 Epsilon:0.05 Duration:38.32 Step:2309 CStep:610586\n",
            "Episode:327 Time:11:54:14 Reward:11.00 Loss:2.68 Last_100_Avg_Rew:8.010 Avg_Max_Q:1.138 Epsilon:0.05 Duration:37.53 Step:2270 CStep:612857\n",
            "Episode:328 Time:11:54:53 Reward:11.00 Loss:2.98 Last_100_Avg_Rew:8.200 Avg_Max_Q:1.137 Epsilon:0.05 Duration:39.49 Step:2352 CStep:615210\n",
            "Episode:329 Time:11:55:27 Reward:17.00 Loss:2.53 Last_100_Avg_Rew:8.440 Avg_Max_Q:1.135 Epsilon:0.05 Duration:33.48 Step:2003 CStep:617214\n",
            "Episode:330 Time:11:56:00 Reward:15.00 Loss:2.47 Last_100_Avg_Rew:8.640 Avg_Max_Q:1.139 Epsilon:0.05 Duration:32.86 Step:1982 CStep:619197\n",
            "Episode:331 Time:11:56:32 Reward:17.00 Loss:2.35 Last_100_Avg_Rew:8.720 Avg_Max_Q:1.127 Epsilon:0.05 Duration:32.12 Step:1939 CStep:621137\n",
            "Episode:332 Time:11:57:13 Reward:9.00 Loss:2.84 Last_100_Avg_Rew:8.990 Avg_Max_Q:1.136 Epsilon:0.05 Duration:40.63 Step:2438 CStep:623576\n",
            "Episode:333 Time:11:57:51 Reward:9.00 Loss:2.67 Last_100_Avg_Rew:9.120 Avg_Max_Q:1.141 Epsilon:0.05 Duration:38.01 Step:2229 CStep:625806\n",
            "Episode:334 Time:11:58:25 Reward:16.00 Loss:2.27 Last_100_Avg_Rew:9.210 Avg_Max_Q:1.128 Epsilon:0.05 Duration:34.05 Step:2047 CStep:627854\n",
            "Episode:335 Time:11:58:54 Reward:19.00 Loss:2.13 Last_100_Avg_Rew:9.310 Avg_Max_Q:1.107 Epsilon:0.05 Duration:29.46 Step:1789 CStep:629644\n",
            "Episode:336 Time:11:59:30 Reward:15.00 Loss:2.48 Last_100_Avg_Rew:9.410 Avg_Max_Q:1.112 Epsilon:0.05 Duration:35.77 Step:2154 CStep:631799\n",
            "Episode:337 Time:12:00:06 Reward:18.00 Loss:2.49 Last_100_Avg_Rew:9.530 Avg_Max_Q:1.127 Epsilon:0.05 Duration:36.39 Step:2200 CStep:634000\n",
            "Episode:338 Time:12:00:43 Reward:13.00 Loss:2.57 Last_100_Avg_Rew:9.650 Avg_Max_Q:1.136 Epsilon:0.05 Duration:37.14 Step:2236 CStep:636237\n",
            "Episode:339 Time:12:01:18 Reward:15.00 Loss:2.35 Last_100_Avg_Rew:9.860 Avg_Max_Q:1.140 Epsilon:0.05 Duration:34.91 Step:2044 CStep:638282\n",
            "Episode:340 Time:12:01:57 Reward:7.00 Loss:2.43 Last_100_Avg_Rew:9.900 Avg_Max_Q:1.142 Epsilon:0.05 Duration:38.74 Step:2326 CStep:640609\n",
            "Episode:341 Time:12:02:44 Reward:-7.00 Loss:3.18 Last_100_Avg_Rew:9.780 Avg_Max_Q:1.133 Epsilon:0.05 Duration:47.11 Step:2869 CStep:643479\n",
            "Episode:342 Time:12:03:24 Reward:9.00 Loss:3.13 Last_100_Avg_Rew:9.830 Avg_Max_Q:1.142 Epsilon:0.05 Duration:39.89 Step:2398 CStep:645878\n",
            "Episode:343 Time:12:04:06 Reward:11.00 Loss:3.07 Last_100_Avg_Rew:9.840 Avg_Max_Q:1.141 Epsilon:0.05 Duration:41.50 Step:2501 CStep:648380\n",
            "Episode:344 Time:12:04:43 Reward:11.00 Loss:2.62 Last_100_Avg_Rew:9.870 Avg_Max_Q:1.131 Epsilon:0.05 Duration:37.72 Step:2249 CStep:650630\n",
            "Episode:345 Time:12:05:27 Reward:7.00 Loss:2.81 Last_100_Avg_Rew:9.790 Avg_Max_Q:1.137 Epsilon:0.05 Duration:43.45 Step:2619 CStep:653250\n",
            "Episode:346 Time:12:06:00 Reward:18.00 Loss:2.59 Last_100_Avg_Rew:9.920 Avg_Max_Q:1.157 Epsilon:0.05 Duration:32.83 Step:1972 CStep:655223\n",
            "Episode:347 Time:12:06:46 Reward:7.00 Loss:3.33 Last_100_Avg_Rew:9.910 Avg_Max_Q:1.157 Epsilon:0.05 Duration:46.83 Step:2789 CStep:658013\n",
            "Episode:348 Time:12:07:33 Reward:7.00 Loss:3.26 Last_100_Avg_Rew:9.940 Avg_Max_Q:1.140 Epsilon:0.05 Duration:46.23 Step:2579 CStep:660593\n",
            "Episode:349 Time:12:08:18 Reward:8.00 Loss:3.32 Last_100_Avg_Rew:10.040 Avg_Max_Q:1.142 Epsilon:0.05 Duration:45.29 Step:2599 CStep:663193\n",
            "Episode:350 Time:12:08:56 Reward:13.00 Loss:2.83 Last_100_Avg_Rew:10.070 Avg_Max_Q:1.141 Epsilon:0.05 Duration:37.83 Step:2177 CStep:665371\n",
            "Episode:351 Time:12:09:39 Reward:8.00 Loss:3.21 Last_100_Avg_Rew:10.120 Avg_Max_Q:1.136 Epsilon:0.05 Duration:43.33 Step:2525 CStep:667897\n",
            "Episode:352 Time:12:10:14 Reward:16.00 Loss:2.99 Last_100_Avg_Rew:10.240 Avg_Max_Q:1.145 Epsilon:0.05 Duration:35.00 Step:2031 CStep:669929\n",
            "Episode:353 Time:12:10:57 Reward:8.00 Loss:3.64 Last_100_Avg_Rew:10.290 Avg_Max_Q:1.157 Epsilon:0.05 Duration:43.27 Step:2465 CStep:672395\n",
            "Episode:354 Time:12:11:36 Reward:13.00 Loss:3.14 Last_100_Avg_Rew:10.340 Avg_Max_Q:1.149 Epsilon:0.05 Duration:38.69 Step:2139 CStep:674535\n",
            "Episode:355 Time:12:12:27 Reward:7.00 Loss:3.66 Last_100_Avg_Rew:10.430 Avg_Max_Q:1.154 Epsilon:0.05 Duration:51.44 Step:2715 CStep:677251\n",
            "Episode:356 Time:12:13:11 Reward:11.00 Loss:3.38 Last_100_Avg_Rew:10.490 Avg_Max_Q:1.151 Epsilon:0.05 Duration:43.91 Step:2347 CStep:679599\n",
            "Episode:357 Time:12:13:51 Reward:14.00 Loss:3.18 Last_100_Avg_Rew:10.520 Avg_Max_Q:1.137 Epsilon:0.05 Duration:39.43 Step:2170 CStep:681770\n",
            "Episode:358 Time:12:14:27 Reward:14.00 Loss:2.90 Last_100_Avg_Rew:10.560 Avg_Max_Q:1.139 Epsilon:0.05 Duration:36.61 Step:2103 CStep:683874\n",
            "Episode:359 Time:12:15:10 Reward:15.00 Loss:3.08 Last_100_Avg_Rew:10.620 Avg_Max_Q:1.136 Epsilon:0.05 Duration:42.94 Step:2230 CStep:686105\n",
            "Episode:360 Time:12:15:47 Reward:16.00 Loss:2.72 Last_100_Avg_Rew:10.720 Avg_Max_Q:1.128 Epsilon:0.05 Duration:36.90 Step:2133 CStep:688239\n",
            "Episode:361 Time:12:16:22 Reward:15.00 Loss:2.52 Last_100_Avg_Rew:10.880 Avg_Max_Q:1.134 Epsilon:0.05 Duration:34.25 Step:2006 CStep:690246\n",
            "Episode:362 Time:12:17:01 Reward:12.00 Loss:2.77 Last_100_Avg_Rew:10.990 Avg_Max_Q:1.125 Epsilon:0.05 Duration:39.50 Step:2264 CStep:692511\n",
            "Episode:363 Time:12:17:53 Reward:5.00 Loss:3.79 Last_100_Avg_Rew:10.960 Avg_Max_Q:1.139 Epsilon:0.05 Duration:51.91 Step:2907 CStep:695419\n",
            "Episode:364 Time:12:18:33 Reward:13.00 Loss:3.15 Last_100_Avg_Rew:11.010 Avg_Max_Q:1.142 Epsilon:0.05 Duration:39.81 Step:2248 CStep:697668\n",
            "Episode:365 Time:12:19:08 Reward:15.00 Loss:2.81 Last_100_Avg_Rew:11.010 Avg_Max_Q:1.141 Epsilon:0.05 Duration:35.28 Step:2104 CStep:699773\n",
            "Episode:366 Time:12:19:44 Reward:14.00 Loss:2.66 Last_100_Avg_Rew:11.030 Avg_Max_Q:1.136 Epsilon:0.05 Duration:36.34 Step:2086 CStep:701860\n",
            "Episode:367 Time:12:20:27 Reward:13.00 Loss:2.91 Last_100_Avg_Rew:11.090 Avg_Max_Q:1.145 Epsilon:0.05 Duration:42.79 Step:2355 CStep:704216\n",
            "Episode:368 Time:12:21:16 Reward:7.00 Loss:3.33 Last_100_Avg_Rew:11.200 Avg_Max_Q:1.144 Epsilon:0.05 Duration:48.53 Step:2656 CStep:706873\n",
            "Episode:369 Time:12:21:51 Reward:17.00 Loss:2.70 Last_100_Avg_Rew:11.270 Avg_Max_Q:1.150 Epsilon:0.05 Duration:35.46 Step:1908 CStep:708782\n",
            "Episode:370 Time:12:22:29 Reward:12.00 Loss:2.77 Last_100_Avg_Rew:11.260 Avg_Max_Q:1.149 Epsilon:0.05 Duration:37.83 Step:2123 CStep:710906\n",
            "Episode:371 Time:12:23:18 Reward:7.00 Loss:3.74 Last_100_Avg_Rew:11.300 Avg_Max_Q:1.148 Epsilon:0.05 Duration:49.39 Step:2771 CStep:713678\n",
            "Episode:372 Time:12:23:49 Reward:18.00 Loss:2.61 Last_100_Avg_Rew:11.400 Avg_Max_Q:1.153 Epsilon:0.05 Duration:30.82 Step:1810 CStep:715489\n",
            "Episode:373 Time:12:24:24 Reward:15.00 Loss:2.80 Last_100_Avg_Rew:11.430 Avg_Max_Q:1.140 Epsilon:0.05 Duration:34.50 Step:2062 CStep:717552\n",
            "Episode:374 Time:12:24:55 Reward:19.00 Loss:2.29 Last_100_Avg_Rew:11.550 Avg_Max_Q:1.145 Epsilon:0.05 Duration:30.99 Step:1793 CStep:719346\n",
            "Episode:375 Time:12:25:30 Reward:15.00 Loss:2.47 Last_100_Avg_Rew:11.620 Avg_Max_Q:1.137 Epsilon:0.05 Duration:35.14 Step:2038 CStep:721385\n",
            "Episode:376 Time:12:26:05 Reward:16.00 Loss:2.47 Last_100_Avg_Rew:11.720 Avg_Max_Q:1.135 Epsilon:0.05 Duration:35.16 Step:2050 CStep:723436\n",
            "Episode:377 Time:12:26:44 Reward:15.00 Loss:2.51 Last_100_Avg_Rew:11.760 Avg_Max_Q:1.141 Epsilon:0.05 Duration:39.28 Step:2295 CStep:725732\n",
            "Episode:378 Time:12:27:19 Reward:14.00 Loss:2.58 Last_100_Avg_Rew:11.810 Avg_Max_Q:1.161 Epsilon:0.05 Duration:34.39 Step:1984 CStep:727717\n",
            "Episode:379 Time:12:27:56 Reward:12.00 Loss:2.36 Last_100_Avg_Rew:11.900 Avg_Max_Q:1.154 Epsilon:0.05 Duration:37.08 Step:2122 CStep:729840\n",
            "Episode:380 Time:12:28:31 Reward:16.00 Loss:2.44 Last_100_Avg_Rew:12.000 Avg_Max_Q:1.157 Epsilon:0.05 Duration:34.74 Step:2011 CStep:731852\n",
            "Episode:381 Time:12:29:01 Reward:19.00 Loss:2.03 Last_100_Avg_Rew:12.050 Avg_Max_Q:1.149 Epsilon:0.05 Duration:30.32 Step:1701 CStep:733554\n",
            "Episode:382 Time:12:29:37 Reward:15.00 Loss:2.13 Last_100_Avg_Rew:12.320 Avg_Max_Q:1.144 Epsilon:0.05 Duration:36.11 Step:2063 CStep:735618\n",
            "Episode:383 Time:12:30:18 Reward:11.00 Loss:2.68 Last_100_Avg_Rew:12.240 Avg_Max_Q:1.136 Epsilon:0.05 Duration:40.69 Step:2363 CStep:737982\n",
            "Episode:384 Time:12:30:55 Reward:15.00 Loss:2.70 Last_100_Avg_Rew:12.410 Avg_Max_Q:1.126 Epsilon:0.05 Duration:37.26 Step:2206 CStep:740189\n",
            "Episode:385 Time:12:31:24 Reward:20.00 Loss:2.07 Last_100_Avg_Rew:12.490 Avg_Max_Q:1.149 Epsilon:0.05 Duration:29.30 Step:1731 CStep:741921\n",
            "Episode:386 Time:12:32:05 Reward:13.00 Loss:2.55 Last_100_Avg_Rew:12.440 Avg_Max_Q:1.152 Epsilon:0.05 Duration:41.09 Step:2305 CStep:744227\n",
            "Episode:387 Time:12:32:39 Reward:18.00 Loss:2.18 Last_100_Avg_Rew:12.530 Avg_Max_Q:1.153 Epsilon:0.05 Duration:33.95 Step:1815 CStep:746043\n",
            "Episode:388 Time:12:33:27 Reward:8.00 Loss:2.61 Last_100_Avg_Rew:12.410 Avg_Max_Q:1.145 Epsilon:0.05 Duration:47.35 Step:2572 CStep:748616\n",
            "Episode:389 Time:12:33:57 Reward:19.00 Loss:1.91 Last_100_Avg_Rew:12.510 Avg_Max_Q:1.144 Epsilon:0.05 Duration:30.28 Step:1728 CStep:750345\n",
            "Episode:390 Time:12:34:32 Reward:17.00 Loss:2.03 Last_100_Avg_Rew:12.590 Avg_Max_Q:1.145 Epsilon:0.05 Duration:35.42 Step:2065 CStep:752411\n",
            "Episode:391 Time:12:35:19 Reward:11.00 Loss:2.72 Last_100_Avg_Rew:12.630 Avg_Max_Q:1.145 Epsilon:0.05 Duration:47.18 Step:2603 CStep:755015\n",
            "Episode:392 Time:12:36:01 Reward:14.00 Loss:2.82 Last_100_Avg_Rew:12.730 Avg_Max_Q:1.141 Epsilon:0.05 Duration:41.02 Step:2288 CStep:757304\n",
            "Episode:393 Time:12:36:38 Reward:14.00 Loss:2.48 Last_100_Avg_Rew:12.770 Avg_Max_Q:1.145 Epsilon:0.05 Duration:37.14 Step:2068 CStep:759373\n",
            "Episode:394 Time:12:37:17 Reward:13.00 Loss:2.62 Last_100_Avg_Rew:12.730 Avg_Max_Q:1.152 Epsilon:0.05 Duration:39.01 Step:2292 CStep:761666\n",
            "Episode:395 Time:12:37:55 Reward:12.00 Loss:2.50 Last_100_Avg_Rew:12.700 Avg_Max_Q:1.151 Epsilon:0.05 Duration:38.17 Step:2250 CStep:763917\n",
            "Episode:396 Time:12:38:35 Reward:13.00 Loss:2.70 Last_100_Avg_Rew:12.630 Avg_Max_Q:1.143 Epsilon:0.05 Duration:40.23 Step:2358 CStep:766276\n",
            "Episode:397 Time:12:39:12 Reward:13.00 Loss:2.68 Last_100_Avg_Rew:12.620 Avg_Max_Q:1.138 Epsilon:0.05 Duration:37.22 Step:2167 CStep:768444\n",
            "Episode:398 Time:12:39:43 Reward:18.00 Loss:2.24 Last_100_Avg_Rew:12.690 Avg_Max_Q:1.148 Epsilon:0.05 Duration:30.99 Step:1820 CStep:770265\n",
            "Episode:399 Time:12:40:17 Reward:14.00 Loss:2.23 Last_100_Avg_Rew:12.670 Avg_Max_Q:1.152 Epsilon:0.05 Duration:34.00 Step:2029 CStep:772295\n",
            "Episode:400 Time:12:40:49 Reward:17.00 Loss:1.97 Last_100_Avg_Rew:12.670 Avg_Max_Q:1.143 Epsilon:0.05 Duration:31.46 Step:1852 CStep:774148\n",
            "Episode:401 Time:12:41:30 Reward:8.00 Loss:2.37 Last_100_Avg_Rew:12.580 Avg_Max_Q:1.146 Epsilon:0.05 Duration:41.61 Step:2474 CStep:776623\n",
            "Episode:402 Time:12:42:06 Reward:15.00 Loss:2.16 Last_100_Avg_Rew:12.680 Avg_Max_Q:1.147 Epsilon:0.05 Duration:35.56 Step:2073 CStep:778697\n",
            "Episode:403 Time:12:42:48 Reward:9.00 Loss:2.51 Last_100_Avg_Rew:12.620 Avg_Max_Q:1.147 Epsilon:0.05 Duration:42.54 Step:2483 CStep:781181\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "aJIvKmeBiR1x"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}